{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 1. Environment Setup\n",
        "# --------------------\n",
        "print(\"Phase 1: Environment Setup\")\n",
        "print(\"==========================\")\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Google Drive mounted successfully.\")\n",
        "except Exception as e:\n",
        "    print(\"Google Drive mount not required or failed:\", e)\n",
        "\n",
        "import subprocess\n",
        "print(\"Installing/Updating Ultralytics and other necessary packages...\")\n",
        "try:\n",
        "    # Ensure ultralytics is up-to-date for latest QAT features if any\n",
        "    subprocess.run([\"pip\", \"install\", \"--upgrade\", \"ultralytics\", \"torchvision\", \"torchaudio\"], check=True)\n",
        "    subprocess.run([\"pip\", \"install\", \"roboflow\", \"tqdm\", \"pandas\", \"seaborn\", \"matplotlib\", \"pyyaml\", \"scipy\"], check=True) # Added scipy for k-means\n",
        "    print(\"Packages installed/updated successfully.\")\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"Error installing packages: {e}\")\n",
        "    raise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1KOl0wFrJVX",
        "outputId": "b361b2be-419e-4ec7-82bd-43ee6ba92a22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phase 1: Environment Setup\n",
            "==========================\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive mounted successfully.\n",
            "Installing/Updating Ultralytics and other necessary packages...\n",
            "Packages installed/updated successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ip install torch torchvision torchaudio ultralytics tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFQqohRarMom",
        "outputId": "630cf8ed-c912-4a58-e19e-a34d6ad1da63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Object \"install\" is unknown, try \"ip help\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import yaml\n",
        "import numpy as np\n",
        "from scipy.cluster.vq import kmeans\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from ultralytics import YOLO\n",
        "from torch.ao.quantization import QuantStub, DeQuantStub\n",
        "from ultralytics.nn.modules import Conv, C2f, Detect, Concat # Import building blocks\n",
        "from tqdm import tqdm as tqdm_iterator # Renamed to avoid conflict with YOLO's internal tqdm\n",
        "from IPython.display import Image, display # For displaying plots in Colab\n",
        "from ultralytics.utils.plotting import plot_results as ultralytics_plot_results # Alias for clarity\n",
        "from torch.ao.quantization import QuantStub, DeQuantStub\n",
        "\n",
        "\n",
        "print(\"All initial imports and setup completed.\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JC4Xs7hSrHJH",
        "outputId": "c628db1c-12fb-4d03-e8c8-76f02e6b0d5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All initial imports and setup completed.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLO12n model\n",
        "model = YOLO('yolo12n.pt')\n",
        "\n",
        "# Create dummy input tensor\n",
        "dummy_input = torch.randn(1, 3, 640, 640)\n",
        "\n",
        "# Extract backbone layers (all but the last Detect layer)\n",
        "layers = model.model.model[:-1]\n",
        "\n",
        "# Forward pass through the backbone, correctly handling Concat layers\n",
        "outputs = []\n",
        "x = dummy_input\n",
        "for layer in layers:\n",
        "    if layer.f != -1:\n",
        "        x = layer([outputs[i] for i in layer.f])\n",
        "    else:\n",
        "        x = layer(x)\n",
        "    outputs.append(x)\n",
        "\n",
        "# Last three outputs are backbone outputs (feature maps)\n",
        "p3, p4, p5 = outputs[-3], outputs[-2], outputs[-1]\n",
        "\n",
        "print(\"✅ Backbone Feature Maps:\")\n",
        "print(f\"P3 shape: {p3.shape}\")\n",
        "print(f\"P4 shape: {p4.shape}\")\n",
        "print(f\"P5 shape: {p5.shape}\")\n",
        "\n",
        "# Inspect Detection Head configuration robustly\n",
        "detect_layer = model.model.model[-1]\n",
        "\n",
        "print(\"\\n🔎 Detection Head Configuration:\")\n",
        "anchors = getattr(detect_layer, 'anchors', None)\n",
        "print(\"Anchors:\", anchors if anchors is not None else \"Anchor-free\")\n",
        "\n",
        "strides = getattr(detect_layer, 'stride', None)\n",
        "print(\"Strides:\", strides.tolist() if strides is not None else \"Not found\")\n",
        "\n",
        "nl = getattr(detect_layer, 'nl', len(strides) if strides is not None else \"Unknown\")\n",
        "print(\"Number of detection layers (nl):\", nl)\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gB1c5ZorGHf",
        "outputId": "793dbc9b-8887-4b73-e2ca-652b7e9f588a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Backbone Feature Maps:\n",
            "P3 shape: torch.Size([1, 128, 20, 20])\n",
            "P4 shape: torch.Size([1, 384, 20, 20])\n",
            "P5 shape: torch.Size([1, 256, 20, 20])\n",
            "\n",
            "🔎 Detection Head Configuration:\n",
            "Anchors: tensor([[ 0.5000,  1.5000,  2.5000,  ...,  8.5000,  9.5000, 10.5000],\n",
            "        [ 0.5000,  0.5000,  0.5000,  ..., 20.5000, 20.5000, 20.5000]])\n",
            "Strides: [8.0, 16.0, 32.0]\n",
            "Number of detection layers (nl): 3\n",
            "YOLO(\n",
            "  (model): DetectionModel(\n",
            "    (model): Sequential(\n",
            "      (0): Conv(\n",
            "        (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (1): Conv(\n",
            "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (2): C3k2(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): ModuleList(\n",
            "          (0): Bottleneck(\n",
            "            (cv1): Conv(\n",
            "              (conv): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(8, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv2): Conv(\n",
            "              (conv): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (3): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (4): C3k2(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): ModuleList(\n",
            "          (0): Bottleneck(\n",
            "            (cv1): Conv(\n",
            "              (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv2): Conv(\n",
            "              (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (5): Conv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (6): A2C2f(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): ModuleList(\n",
            "          (0-1): 2 x Sequential(\n",
            "            (0): ABlock(\n",
            "              (attn): AAttn(\n",
            "                (qkv): Conv(\n",
            "                  (conv): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                  (act): Identity()\n",
            "                )\n",
            "                (proj): Conv(\n",
            "                  (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                  (act): Identity()\n",
            "                )\n",
            "                (pe): Conv(\n",
            "                  (conv): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\n",
            "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                  (act): Identity()\n",
            "                )\n",
            "              )\n",
            "              (mlp): Sequential(\n",
            "                (0): Conv(\n",
            "                  (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                  (act): SiLU(inplace=True)\n",
            "                )\n",
            "                (1): Conv(\n",
            "                  (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                  (act): Identity()\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "            (1): ABlock(\n",
            "              (attn): AAttn(\n",
            "                (qkv): Conv(\n",
            "                  (conv): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                  (act): Identity()\n",
            "                )\n",
            "                (proj): Conv(\n",
            "                  (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                  (act): Identity()\n",
            "                )\n",
            "                (pe): Conv(\n",
            "                  (conv): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\n",
            "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                  (act): Identity()\n",
            "                )\n",
            "              )\n",
            "              (mlp): Sequential(\n",
            "                (0): Conv(\n",
            "                  (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                  (act): SiLU(inplace=True)\n",
            "                )\n",
            "                (1): Conv(\n",
            "                  (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                  (act): Identity()\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (7): Conv(\n",
            "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (8): A2C2f(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): ModuleList(\n",
            "          (0-1): 2 x Sequential(\n",
            "            (0): ABlock(\n",
            "              (attn): AAttn(\n",
            "                (qkv): Conv(\n",
            "                  (conv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                  (act): Identity()\n",
            "                )\n",
            "                (proj): Conv(\n",
            "                  (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                  (act): Identity()\n",
            "                )\n",
            "                (pe): Conv(\n",
            "                  (conv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
            "                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                  (act): Identity()\n",
            "                )\n",
            "              )\n",
            "              (mlp): Sequential(\n",
            "                (0): Conv(\n",
            "                  (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                  (act): SiLU(inplace=True)\n",
            "                )\n",
            "                (1): Conv(\n",
            "                  (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                  (act): Identity()\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "            (1): ABlock(\n",
            "              (attn): AAttn(\n",
            "                (qkv): Conv(\n",
            "                  (conv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                  (act): Identity()\n",
            "                )\n",
            "                (proj): Conv(\n",
            "                  (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                  (act): Identity()\n",
            "                )\n",
            "                (pe): Conv(\n",
            "                  (conv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
            "                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                  (act): Identity()\n",
            "                )\n",
            "              )\n",
            "              (mlp): Sequential(\n",
            "                (0): Conv(\n",
            "                  (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                  (act): SiLU(inplace=True)\n",
            "                )\n",
            "                (1): Conv(\n",
            "                  (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                  (act): Identity()\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (9): Upsample(scale_factor=2.0, mode='nearest')\n",
            "      (10): Concat()\n",
            "      (11): A2C2f(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): ModuleList(\n",
            "          (0): C3k(\n",
            "            (cv1): Conv(\n",
            "              (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv2): Conv(\n",
            "              (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv3): Conv(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (m): Sequential(\n",
            "              (0): Bottleneck(\n",
            "                (cv1): Conv(\n",
            "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                  (act): SiLU(inplace=True)\n",
            "                )\n",
            "                (cv2): Conv(\n",
            "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                  (act): SiLU(inplace=True)\n",
            "                )\n",
            "              )\n",
            "              (1): Bottleneck(\n",
            "                (cv1): Conv(\n",
            "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                  (act): SiLU(inplace=True)\n",
            "                )\n",
            "                (cv2): Conv(\n",
            "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                  (act): SiLU(inplace=True)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (12): Upsample(scale_factor=2.0, mode='nearest')\n",
            "      (13): Concat()\n",
            "      (14): A2C2f(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): ModuleList(\n",
            "          (0): C3k(\n",
            "            (cv1): Conv(\n",
            "              (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv2): Conv(\n",
            "              (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv3): Conv(\n",
            "              (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (m): Sequential(\n",
            "              (0): Bottleneck(\n",
            "                (cv1): Conv(\n",
            "                  (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                  (act): SiLU(inplace=True)\n",
            "                )\n",
            "                (cv2): Conv(\n",
            "                  (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                  (act): SiLU(inplace=True)\n",
            "                )\n",
            "              )\n",
            "              (1): Bottleneck(\n",
            "                (cv1): Conv(\n",
            "                  (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                  (act): SiLU(inplace=True)\n",
            "                )\n",
            "                (cv2): Conv(\n",
            "                  (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                  (act): SiLU(inplace=True)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (15): Conv(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (16): Concat()\n",
            "      (17): A2C2f(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): ModuleList(\n",
            "          (0): C3k(\n",
            "            (cv1): Conv(\n",
            "              (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv2): Conv(\n",
            "              (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv3): Conv(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (m): Sequential(\n",
            "              (0): Bottleneck(\n",
            "                (cv1): Conv(\n",
            "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                  (act): SiLU(inplace=True)\n",
            "                )\n",
            "                (cv2): Conv(\n",
            "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                  (act): SiLU(inplace=True)\n",
            "                )\n",
            "              )\n",
            "              (1): Bottleneck(\n",
            "                (cv1): Conv(\n",
            "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                  (act): SiLU(inplace=True)\n",
            "                )\n",
            "                (cv2): Conv(\n",
            "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                  (act): SiLU(inplace=True)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (18): Conv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (19): Concat()\n",
            "      (20): C3k2(\n",
            "        (cv1): Conv(\n",
            "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (cv2): Conv(\n",
            "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (m): ModuleList(\n",
            "          (0): C3k(\n",
            "            (cv1): Conv(\n",
            "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv2): Conv(\n",
            "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (cv3): Conv(\n",
            "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (m): Sequential(\n",
            "              (0): Bottleneck(\n",
            "                (cv1): Conv(\n",
            "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                  (act): SiLU(inplace=True)\n",
            "                )\n",
            "                (cv2): Conv(\n",
            "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                  (act): SiLU(inplace=True)\n",
            "                )\n",
            "              )\n",
            "              (1): Bottleneck(\n",
            "                (cv1): Conv(\n",
            "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                  (act): SiLU(inplace=True)\n",
            "                )\n",
            "                (cv2): Conv(\n",
            "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                  (act): SiLU(inplace=True)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (21): Detect(\n",
            "        (cv2): ModuleList(\n",
            "          (0): Sequential(\n",
            "            (0): Conv(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (1): Sequential(\n",
            "            (0): Conv(\n",
            "              (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (2): Sequential(\n",
            "            (0): Conv(\n",
            "              (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv(\n",
            "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "              (act): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "        (cv3): ModuleList(\n",
            "          (0): Sequential(\n",
            "            (0): Sequential(\n",
            "              (0): DWConv(\n",
            "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
            "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (1): Conv(\n",
            "                (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "            (1): Sequential(\n",
            "              (0): DWConv(\n",
            "                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n",
            "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (1): Conv(\n",
            "                (conv): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (1): Sequential(\n",
            "            (0): Sequential(\n",
            "              (0): DWConv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
            "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (1): Conv(\n",
            "                (conv): Conv2d(128, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "            (1): Sequential(\n",
            "              (0): DWConv(\n",
            "                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n",
            "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (1): Conv(\n",
            "                (conv): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (2): Sequential(\n",
            "            (0): Sequential(\n",
            "              (0): DWConv(\n",
            "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
            "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (1): Conv(\n",
            "                (conv): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "            (1): Sequential(\n",
            "              (0): DWConv(\n",
            "                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n",
            "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (1): Conv(\n",
            "                (conv): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "        (dfl): DFL(\n",
            "          (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJAN5AMSpoT1",
        "outputId": "4f3b0069-fb5d-4912-fa36-4d48b076dc71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Phase 2: Enhanced Custom Enhancement Modules\n",
            "==========================================\n",
            "Enhanced custom modules defined.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 2. Enhanced Custom Enhancement Modules\n",
        "# ------------------------------------\n",
        "print(\"\\nPhase 2: Enhanced Custom Enhancement Modules\")\n",
        "print(\"==========================================\")\n",
        "\n",
        "class CBAM(nn.Module):\n",
        "    def __init__(self, channels, reduction_ratio=8):  # Reduced ratio for stronger attention\n",
        "        super().__init__()\n",
        "        # Enhanced channel attention with both avg and max pooling\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Conv2d(channels, channels // reduction_ratio, 1, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(channels // reduction_ratio, channels, 1, bias=False)\n",
        "        )\n",
        "        self.sigmoid_channel = nn.Sigmoid()\n",
        "\n",
        "        # Spatial attention with larger kernel for better spatial context\n",
        "        self.spatial_conv = nn.Conv2d(2, 1, kernel_size=7, padding=3, bias=False)\n",
        "        self.sigmoid_spatial = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Channel attention with both avg and max pooling\n",
        "        avg_out = self.mlp(self.avg_pool(x))\n",
        "        max_out = self.mlp(self.max_pool(x))\n",
        "        ca_weights = self.sigmoid_channel(avg_out + max_out)\n",
        "        x_ca = ca_weights * x\n",
        "\n",
        "        # Spatial attention\n",
        "        avg_spatial = torch.mean(x_ca, dim=1, keepdim=True)\n",
        "        max_spatial = torch.max(x_ca, dim=1, keepdim=True)[0]\n",
        "        sa_input = torch.cat([avg_spatial, max_spatial], dim=1)\n",
        "        sa_weights = self.sigmoid_spatial(self.spatial_conv(sa_input))\n",
        "        x_sa = sa_weights * x_ca\n",
        "        return x_sa\n",
        "\n",
        "class TransformerEncoderBlock(nn.Module):\n",
        "    def __init__(self, channels, num_heads=4, num_layers=2, dim_feedforward=None, dropout=0.1):\n",
        "        super().__init__()\n",
        "        if dim_feedforward is None:\n",
        "            dim_feedforward = channels * 4  # Increased from 2x to 4x for better feature extraction\n",
        "\n",
        "        self.channels = channels\n",
        "        # Add positional embedding for better spatial awareness\n",
        "        self.pos_embedding = nn.Parameter(torch.zeros(1, 256, channels))\n",
        "        nn.init.trunc_normal_(self.pos_embedding, std=0.02)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=channels,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout,\n",
        "            batch_first=True,\n",
        "            activation=F.gelu  # Changed from ReLU to GELU for better gradient flow\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.norm = nn.LayerNorm(channels)\n",
        "\n",
        "        # For QAT compatibility\n",
        "        self.quant = torch.quantization.QuantStub()\n",
        "        self.dequant = torch.quantization.DeQuantStub()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Save original for residual connection\n",
        "        x_orig = x\n",
        "        x = self.dequant(x)\n",
        "\n",
        "        b, c, h, w = x.size()\n",
        "        seq_len = h * w\n",
        "\n",
        "        # Reshape and add positional embeddings\n",
        "        seq = x.view(b, c, -1).permute(0, 2, 1)  # [B, HW, C]\n",
        "\n",
        "        # Adapt positional embedding to the current sequence length\n",
        "        if seq_len <= self.pos_embedding.shape[1]:\n",
        "            pos_embed = self.pos_embedding[:, :seq_len, :]\n",
        "        else:\n",
        "            pos_embed = F.interpolate(\n",
        "                self.pos_embedding.permute(0, 2, 1),\n",
        "                size=seq_len,\n",
        "                mode='linear'\n",
        "            ).permute(0, 2, 1)\n",
        "\n",
        "        seq = seq + pos_embed\n",
        "        seq = self.norm(seq)  # Pre-norm for better stability\n",
        "\n",
        "        # Apply transformer\n",
        "        seq_out = self.transformer_encoder(seq)\n",
        "\n",
        "        # Reshape back to spatial\n",
        "        x_out = seq_out.permute(0, 2, 1).view(b, c, h, w)\n",
        "\n",
        "        # Skip connection for stability\n",
        "        x_out = x_out + x_orig\n",
        "\n",
        "        # Requantize after Transformer\n",
        "        x_out = self.quant(x_out)\n",
        "        return x_out\n",
        "\n",
        "class SmallObjectFeatures(nn.Module):\n",
        "    def __init__(self, in_channels, feature_channels=128):\n",
        "        super().__init__()\n",
        "        # Expanded architecture for better small object detection\n",
        "        self.conv_block = nn.Sequential(\n",
        "            Conv(in_channels, feature_channels, k=3, p=1),\n",
        "            Conv(feature_channels, feature_channels, k=3, p=1, d=2),  # Added dilation for larger receptive field\n",
        "            Conv(feature_channels, feature_channels, k=3, p=1),\n",
        "            Conv(feature_channels, feature_channels, k=3, p=1, s=1)   # Maintain resolution\n",
        "        )\n",
        "\n",
        "        # Add CBAM attention specifically for small objects\n",
        "        self.attention = CBAM(feature_channels, reduction_ratio=4)  # More aggressive reduction for small objects\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_block(x)\n",
        "        x = self.attention(x)\n",
        "        return x\n",
        "\n",
        "class BiFPN_FusionNode(nn.Module):\n",
        "    def __init__(self, in_channels_high_res, in_channels_low_res, out_channels):\n",
        "        super().__init__()\n",
        "        # Enhanced with weighted fusion\n",
        "        self.w1 = nn.Parameter(torch.ones(2, dtype=torch.float32), requires_grad=True)\n",
        "        self.epsilon = 1e-4\n",
        "\n",
        "        # Improved convolutions\n",
        "        self.conv_high_res = Conv(in_channels_high_res, out_channels, k=1, p=0)\n",
        "        self.conv_low_res = Conv(in_channels_low_res, out_channels, k=1, p=0)\n",
        "\n",
        "        # Enhanced fusion with residual connection\n",
        "        self.merge_conv1 = Conv(out_channels, out_channels, k=3, p=1)\n",
        "        self.merge_conv2 = Conv(out_channels, out_channels, k=3, p=1)\n",
        "\n",
        "    def forward(self, x_high_res, x_low_res):\n",
        "        # Get normalized weights\n",
        "        w = F.relu(self.w1)\n",
        "        w = w / (torch.sum(w, dim=0) + self.epsilon)\n",
        "\n",
        "        # Process features\n",
        "        feat_high = self.conv_high_res(x_high_res)\n",
        "        x_low_res_processed = self.conv_low_res(x_low_res)\n",
        "\n",
        "        # Upsample if needed\n",
        "        if x_low_res.shape[2:] != x_high_res.shape[2:]:\n",
        "            x_low_res_upsampled = F.interpolate(\n",
        "                x_low_res_processed,\n",
        "                size=x_high_res.shape[2:],\n",
        "                mode='bilinear',  # Changed from nearest to bilinear for smoother features\n",
        "                align_corners=False\n",
        "            )\n",
        "        else:\n",
        "            x_low_res_upsampled = x_low_res_processed\n",
        "\n",
        "        # Weighted fusion\n",
        "        fused = w[0] * feat_high + w[1] * x_low_res_upsampled\n",
        "\n",
        "        # Enhanced processing with residual connection\n",
        "        out = self.merge_conv1(fused)\n",
        "        out = self.merge_conv2(out) + out  # Residual connection\n",
        "\n",
        "        return out\n",
        "\n",
        "# Enhanced DFL Loss for better distribution prediction\n",
        "class EnhancedDFLLoss(nn.Module):\n",
        "    def __init__(self, reg_max=16):\n",
        "        super(EnhancedDFLLoss, self).__init__()\n",
        "        self.reg_max = reg_max\n",
        "        self.register_buffer('proj', torch.arange(0, reg_max).float())\n",
        "\n",
        "    def forward(self, pred_dist, target):\n",
        "        # Create target distribution using a Gaussian instead of one-hot\n",
        "        b, a, c, h, w = pred_dist.shape\n",
        "        pred_dist = pred_dist.view(b, a, c, -1)\n",
        "\n",
        "        target_expanded = target.unsqueeze(-1)\n",
        "        tl = torch.floor(target_expanded)\n",
        "        tu = torch.ceil(target_expanded)\n",
        "\n",
        "        # Create soft distribution using Gaussian around the target\n",
        "        sigma = 0.5\n",
        "\n",
        "        expanded_proj = self.proj.view(1, 1, -1, 1).expand(b, a, -1, h*w)\n",
        "        gauss_weight_l = torch.exp(-((expanded_proj - tl) ** 2) / (2 * sigma ** 2))\n",
        "        gauss_weight_u = torch.exp(-((expanded_proj - tu) ** 2) / (2 * sigma ** 2))\n",
        "\n",
        "        # Normalize to sum to 1\n",
        "        soft_targets = gauss_weight_l + gauss_weight_u\n",
        "        soft_targets = soft_targets / (soft_targets.sum(dim=2, keepdim=True) + 1e-12)\n",
        "\n",
        "        # Cross entropy loss on distributions\n",
        "        loss = F.cross_entropy(\n",
        "            pred_dist.permute(0, 1, 3, 2),\n",
        "            soft_targets.permute(0, 1, 3, 2),\n",
        "            reduction='none'\n",
        "        )\n",
        "\n",
        "        return loss.mean()\n",
        "\n",
        "print(\"Enhanced custom modules defined.\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Fixed Enhanced YOLO Model Structure\n",
        "# ---------------------------------------------\n",
        "print(\"\\nPhase 3: Fixed Enhanced YOLO Model Structure\")\n",
        "print(\"======================================================\")\n",
        "\n",
        "class ModifiedYOLOBackbone(nn.Module):\n",
        "    def __init__(self, original_model_sequential):\n",
        "        super().__init__()\n",
        "        self.layers = list(original_model_sequential.children())\n",
        "        # Fixed tap points based on YOLOv12n structure\n",
        "        self.p3_tap_idx = 4  # P3 features\n",
        "        self.p4_tap_idx = 6  # P4 features\n",
        "        self.p5_tap_idx = 8  # P5 features\n",
        "\n",
        "        self.stage1 = nn.Sequential(*self.layers[0:self.p3_tap_idx+1])\n",
        "        self.stage2 = nn.Sequential(*self.layers[self.p3_tap_idx+1:self.p4_tap_idx+1])\n",
        "        self.stage3 = nn.Sequential(*self.layers[self.p4_tap_idx+1:self.p5_tap_idx+1])\n",
        "\n",
        "        # Feature enhancement connections\n",
        "        self.lateral_p5_p4 = Conv(256, 384, k=1)  # P5 to P4 lateral connection\n",
        "        self.lateral_p4_p3 = Conv(384, 128, k=1)  # P4 to P3 lateral connection\n",
        "\n",
        "        # CRITICAL: Add the f attribute that Ultralytics expects for export\n",
        "        self.f = -1  # Add this to fix the export error\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Process through backbone stages\n",
        "        p3_feat = self.stage1(x)\n",
        "        p4_feat = self.stage2(p3_feat)\n",
        "        p5_feat = self.stage3(p4_feat)\n",
        "\n",
        "        # FPN-like enhancement\n",
        "        p5_up = F.interpolate(self.lateral_p5_p4(p5_feat), scale_factor=2, mode='bilinear', align_corners=False)\n",
        "        p4_enhanced = p4_feat + p5_up\n",
        "\n",
        "        p4_up = F.interpolate(self.lateral_p4_p3(p4_enhanced), scale_factor=2, mode='bilinear', align_corners=False)\n",
        "        p3_enhanced = p3_feat + p4_up\n",
        "\n",
        "        return p3_enhanced, p4_enhanced, p5_feat\n",
        "\n",
        "class CustomEnhancedYOLOModel(nn.Module):\n",
        "    def __init__(self, base_model_instance, nc):\n",
        "        super().__init__()\n",
        "        self.nc = nc\n",
        "        original_sequential_model = base_model_instance.model.model\n",
        "\n",
        "        # Enhanced backbone\n",
        "        self.modified_backbone = ModifiedYOLOBackbone(original_sequential_model)\n",
        "\n",
        "        # Channel dimensions\n",
        "        self.ch_p3_tap = 128\n",
        "        self.ch_p4_tap = 384\n",
        "        self.ch_p5_tap = 256\n",
        "\n",
        "        # Enhanced feature processing\n",
        "        self.cbam_p3 = CBAM(self.ch_p3_tap)\n",
        "        self.cbam_p4 = CBAM(self.ch_p4_tap)\n",
        "        self.cbam_p5 = CBAM(self.ch_p5_tap)\n",
        "\n",
        "        # Transformers for higher-level features\n",
        "        self.transformer_p3 = TransformerEncoderBlock(self.ch_p3_tap, num_heads=2)\n",
        "        self.transformer_p4 = TransformerEncoderBlock(self.ch_p4_tap, num_heads=4)\n",
        "        self.transformer_p5 = TransformerEncoderBlock(self.ch_p5_tap, num_heads=4)\n",
        "\n",
        "        # Increased channel dimensions for richer features\n",
        "        self.neck_out_ch_p3 = 128  # Increased from 96\n",
        "        self.neck_out_ch_p4 = 192  # Increased from 128\n",
        "        self.neck_out_ch_p5 = 256  # Increased from 192\n",
        "\n",
        "        # Feature fusion\n",
        "        self.bifpn_p4_neck = BiFPN_FusionNode(self.neck_out_ch_p3, self.ch_p4_tap, self.neck_out_ch_p4)\n",
        "        self.bifpn_p5_neck = BiFPN_FusionNode(self.neck_out_ch_p4, self.ch_p5_tap, self.neck_out_ch_p5)\n",
        "\n",
        "        # YOLOv12 strides - keep as-is since YOLOv12 is anchor-free\n",
        "        self.strides = torch.tensor([8.0, 16.0, 32.0])\n",
        "        self.is_qat_enabled = False  # Default off, set True explicitly during training\n",
        "\n",
        "        # Get the original detect head for reference\n",
        "        base_detect = base_model_instance.model.model[-1]\n",
        "\n",
        "        # Setup the detection head to match YOLOv12 design\n",
        "        self.detect_head = Detect(\n",
        "            nc=self.nc,\n",
        "            ch=[self.neck_out_ch_p3, self.neck_out_ch_p4, self.neck_out_ch_p5]\n",
        "        )\n",
        "\n",
        "        # Ensure proper stride and other properties\n",
        "        self.detect_head.stride = self.strides\n",
        "        self.stride = self.strides  # For the overall model to have this attribute\n",
        "\n",
        "        # If the detect head has a DFL component, preserve it\n",
        "        if hasattr(base_detect, 'dfl'):\n",
        "            self.detect_head.dfl = base_detect.dfl\n",
        "\n",
        "        # Add enhanced DFL loss\n",
        "        self.enhanced_dfl = EnhancedDFLLoss(reg_max=16)  # Match YOLOv12 reg_max\n",
        "\n",
        "        # QAT support\n",
        "        self.quant = QuantStub()\n",
        "        self.dequant = DeQuantStub()\n",
        "\n",
        "        # Make model subscriptable for export compatibility\n",
        "        self.layers = nn.ModuleList([\n",
        "            self.modified_backbone,\n",
        "            self.cbam_p3, self.cbam_p4, self.cbam_p5,\n",
        "            self.transformer_p3, self.transformer_p4, self.transformer_p5,\n",
        "            self.detect_head\n",
        "        ])\n",
        "\n",
        "        # CRITICAL: Add the f attribute that Ultralytics expects for export\n",
        "        self.f = -1  # Add this to fix the export error\n",
        "\n",
        "    def fuse(self):\n",
        "        print(\"Fusing modules in CustomEnhancedYOLOModel...\")\n",
        "        for m in self.modules():\n",
        "            if type(m) is Conv and hasattr(m, 'bn') and hasattr(m, 'act'):\n",
        "                 m.fuse_convs()\n",
        "        print(\"Fusion complete.\")\n",
        "        return self\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.layers[idx]\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.quant(x)\n",
        "\n",
        "        # Get enhanced features from backbone\n",
        "        p3_feat, p4_feat, p5_feat = self.modified_backbone(x)\n",
        "\n",
        "        # Apply attention and transformer enhancements\n",
        "        p3_enhanced = self.transformer_p3(self.cbam_p3(p3_feat))\n",
        "        p4_enhanced = self.transformer_p4(self.cbam_p4(p4_feat))\n",
        "        p5_enhanced = self.transformer_p5(self.cbam_p5(p5_feat))\n",
        "\n",
        "        # Process P3 features\n",
        "        p3_proj = nn.Sequential(\n",
        "            nn.Conv2d(self.ch_p3_tap, self.neck_out_ch_p3, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(self.neck_out_ch_p3),\n",
        "            nn.SiLU(inplace=True)\n",
        "        )(p3_enhanced)\n",
        "\n",
        "        if self.training and self.is_qat_enabled:\n",
        "            p3_proj = torch.fake_quantize_per_tensor_affine(\n",
        "                p3_proj, scale=1.0/128.0, zero_point=0, quant_min=0, quant_max=255\n",
        "            )\n",
        "\n",
        "        # Process P4 features\n",
        "        p4_proj = nn.Sequential(\n",
        "            nn.Conv2d(self.ch_p4_tap, self.neck_out_ch_p4, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(self.neck_out_ch_p4),\n",
        "            nn.SiLU(inplace=True)\n",
        "        )(p4_enhanced)\n",
        "\n",
        "        if self.training and self.is_qat_enabled:\n",
        "            p4_proj = torch.fake_quantize_per_tensor_affine(\n",
        "                p4_proj, scale=1.0/128.0, zero_point=0, quant_min=0, quant_max=255\n",
        "            )\n",
        "\n",
        "        # Process P5 features\n",
        "        p5_proj = nn.Sequential(\n",
        "            nn.Conv2d(self.ch_p5_tap, self.neck_out_ch_p5, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(self.neck_out_ch_p5),\n",
        "            nn.SiLU(inplace=True)\n",
        "        )(p5_enhanced)\n",
        "\n",
        "        if self.training and self.is_qat_enabled:\n",
        "            p5_proj = torch.fake_quantize_per_tensor_affine(\n",
        "                p5_proj, scale=1.0/128.0, zero_point=0, quant_min=0, quant_max=255\n",
        "            )\n",
        "\n",
        "        # Improved feature fusion\n",
        "        neck_p4 = self.bifpn_p4_neck(p4_proj, p3_proj)\n",
        "        neck_p5 = self.bifpn_p5_neck(p5_proj, neck_p4)\n",
        "\n",
        "        if self.training and self.is_qat_enabled:\n",
        "            neck_p4 = torch.fake_quantize_per_tensor_affine(\n",
        "                neck_p4, scale=1.0/128.0, zero_point=0, quant_min=0, quant_max=255\n",
        "            )\n",
        "            neck_p5 = torch.fake_quantize_per_tensor_affine(\n",
        "                neck_p5, scale=1.0/128.0, zero_point=0, quant_min=0, quant_max=255\n",
        "            )\n",
        "\n",
        "        # Feed features to detection head (keep the order compatible with YOLOv12)\n",
        "        features_for_head = [p3_proj, neck_p4, neck_p5]\n",
        "\n",
        "        detections = self.detect_head(features_for_head)\n",
        "        detections = self.dequant(detections)\n",
        "        return detections\n",
        "\n",
        "print(\"Enhanced anchor-free YOLOv12 model structure defined.\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1v1c-_iqu8O",
        "outputId": "8a4a4ba3-9b36-47ba-9bd4-00f5f8f12e73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Phase 3: Fixed Enhanced YOLO Model Structure\n",
            "======================================================\n",
            "Enhanced anchor-free YOLOv12 model structure defined.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Enhanced Main Script Logic\n",
        "# ---------------------------------------------------------------------------------------\n",
        "print(\"\\nPhase 5: Enhanced Main Script Logic with Improved Training\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Paths (unchanged)\n",
        "drive_base_path = '/content/drive/My Drive/'\n",
        "dataset_root_in_drive = 'SemesterProjectDatas/CombinedData'\n",
        "project_root_in_drive = 'SemesterProjectDatas/Model/Yolo12n/EnhancedYolo12n'\n",
        "\n",
        "combined_dataset_path = os.path.join(drive_base_path, dataset_root_in_drive)\n",
        "data_yaml = os.path.join(combined_dataset_path, 'data.yaml')\n",
        "base_model_name = 'yolo12n.pt'\n",
        "project_dir_enhanced_model = os.path.join(drive_base_path, project_root_in_drive)\n",
        "experiment_name = 'run_yolo12n_enhanced_improved'\n",
        "\n",
        "os.makedirs(project_dir_enhanced_model, exist_ok=True)\n",
        "\n",
        "# Verify YAML\n",
        "assert os.path.exists(data_yaml), f\"ERROR: Dataset YAML file not found at '{data_yaml}'.\"\n",
        "\n",
        "# Load dataset YAML\n",
        "with open(data_yaml, 'r') as f:\n",
        "    dataset_info = yaml.safe_load(f)\n",
        "nc_from_yaml = int(dataset_info['nc'])\n",
        "class_names_from_yaml = dataset_info['names']\n",
        "\n",
        "# Initialize YOLO model\n",
        "managed_model = YOLO(base_model_name)\n",
        "\n",
        "# Instantiate enhanced YOLOv12n model\n",
        "print(\"Initializing enhanced YOLOv12n model with improved architecture...\")\n",
        "custom_model_module = CustomEnhancedYOLOModel(\n",
        "    base_model_instance=managed_model,\n",
        "    nc=nc_from_yaml\n",
        ")\n",
        "\n",
        "# Assign model explicitly\n",
        "managed_model.model.model = custom_model_module\n",
        "managed_model.model.nc = nc_from_yaml\n",
        "managed_model.model.names = dict(enumerate(class_names_from_yaml))\n",
        "\n",
        "if hasattr(custom_model_module, 'stride'):\n",
        "    managed_model.model.stride = custom_model_module.stride\n",
        "\n",
        "# Two-stage training approach for better results\n",
        "# Stage 1: Regular training without QAT\n",
        "print(\"\\nStage 1: Training without QAT (75 epochs)\")\n",
        "print(\"============================================\")\n",
        "\n",
        "# Enhanced training parameters\n",
        "epochs_stage1 = 100\n",
        "image_size = 640  # Increased from 640 for better detection\n",
        "batch_size = 32   # Adjusted for larger image size\n",
        "device_to_use = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "try:\n",
        "    # First stage: Train without QAT\n",
        "    results = managed_model.train(\n",
        "        data=data_yaml,\n",
        "        epochs=epochs_stage1,\n",
        "        imgsz=image_size,\n",
        "        batch=batch_size,\n",
        "        project=project_dir_enhanced_model,\n",
        "        name=experiment_name + \"_stage1\",\n",
        "        exist_ok=True,\n",
        "        device=device_to_use,\n",
        "        patience=25,\n",
        "        optimizer='AdamW',\n",
        "        lr0=0.001,\n",
        "        lrf=0.01,\n",
        "        amp=True,\n",
        "        dropout=0.1,  # Add some dropout for regularization\n",
        "        mosaic=1.0,   # Full mosaic augmentation\n",
        "        mixup=0.3,    # Add mixup\n",
        "        degrees=15.0, # Increased rotation augmentation\n",
        "        translate=0.2, # More translation\n",
        "        copy_paste=0.3, # Add copy-paste for small objects\n",
        "        # Customize loss weights to favor box precision\n",
        "        box=7.5,  # Increased box loss weight\n",
        "        cls=0.5,  # Standard classification weight\n",
        "        dfl=1.5   # Standard DFL weight\n",
        "    )\n",
        "    print(\"✅ Stage 1 training completed successfully.\")\n",
        "    stage1_successful = True\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ ERROR DURING STAGE 1 TRAINING: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    stage1_successful = False\n",
        "\n",
        "# If first stage was successful, proceed to QAT stage\n",
        "if stage1_successful:\n",
        "    print(\"\\nStage 2: QAT fine-tuning for 75 epochs\")\n",
        "    print(\"=======================================\")\n",
        "\n",
        "    # Load best model from stage 1\n",
        "    best_model_path = os.path.join(project_dir_enhanced_model, experiment_name + \"_stage1\", 'weights', 'best.pt')\n",
        "    if os.path.exists(best_model_path):\n",
        "        # Load the best model from stage 1\n",
        "        qat_model = YOLO(best_model_path)\n",
        "\n",
        "        # Enable QAT in the model\n",
        "        if hasattr(qat_model.model.model, 'is_qat_enabled'):\n",
        "            qat_model.model.model.is_qat_enabled = True\n",
        "            print(\"✅ QAT enabled for stage 2 training\")\n",
        "\n",
        "        try:\n",
        "            # Continue training with QAT enabled\n",
        "            results = qat_model.train(\n",
        "                data=data_yaml,\n",
        "                epochs=100,\n",
        "                imgsz=image_size,\n",
        "                batch=batch_size,\n",
        "                project=project_dir_enhanced_model,\n",
        "                name=experiment_name + \"_stage2_qat\",\n",
        "                exist_ok=True,\n",
        "                device=device_to_use,\n",
        "                patience=25,\n",
        "                optimizer='AdamW',\n",
        "                lr0=0.0003,  # Lower learning rate for QAT stage\n",
        "                lrf=0.001,\n",
        "                amp=False,   # Disable mixed precision for QAT\n",
        "                mosaic=0.8,  # Slightly reduce augmentation for fine-tuning\n",
        "                mixup=0.1,\n",
        "                degrees=7.0,\n",
        "                translate=0.1,   # Reduced translation for fine-tuning\n",
        "                copy_paste=0.1,  # Reduced copy-paste for QAT stage\n",
        "                cache=True,      # Cache images for faster training\n",
        "                box=7.5,         # Keep same loss weights for consistency\n",
        "                cls=0.5,\n",
        "                dfl=2.0          # Slightly increase DFL weight for better precision\n",
        "            )\n",
        "            print(\"✅ Stage 2 QAT training completed successfully.\")\n",
        "            qat_training_successful = True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n❌ ERROR DURING STAGE 2 QAT TRAINING: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            qat_training_successful = False\n",
        "\n",
        "        # Post-training INT8 Conversion\n",
        "        if qat_training_successful:\n",
        "            best_qat_model_path = os.path.join(project_dir_enhanced_model, experiment_name + \"_stage2_qat\", 'weights', 'best.pt')\n",
        "\n",
        "            if os.path.exists(best_qat_model_path):\n",
        "                print(\"\\nPerforming post-training INT8 conversion...\")\n",
        "                try:\n",
        "                    # Load the best QAT model\n",
        "                    base_model = YOLO(base_model_name)\n",
        "                    quant_model = CustomEnhancedYOLOModel(\n",
        "                        base_model_instance=base_model,\n",
        "                        nc=nc_from_yaml\n",
        "                    )\n",
        "\n",
        "                    # Load weights correctly\n",
        "                    loaded_weights = torch.load(best_qat_model_path)\n",
        "\n",
        "                    # Check and extract state_dict properly\n",
        "                    if 'model' in loaded_weights:\n",
        "                        detection_model = loaded_weights['model']\n",
        "                        model_state_dict = detection_model.state_dict()\n",
        "                    else:\n",
        "                        model_state_dict = loaded_weights\n",
        "\n",
        "                    quant_model.load_state_dict(model_state_dict, strict=False)\n",
        "                    quant_model.cpu().eval()\n",
        "\n",
        "                    # Configure quantization for INT8 conversion\n",
        "                    quant_model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
        "\n",
        "                    # Skip quantization for Transformer blocks\n",
        "                    for module in quant_model.modules():\n",
        "                        if isinstance(module, (TransformerEncoderBlock, CBAM)):\n",
        "                            module.qconfig = None\n",
        "\n",
        "                    # Prepare and convert the model\n",
        "                    torch.quantization.prepare(quant_model, inplace=True)\n",
        "                    quantized_model = torch.quantization.convert(quant_model)\n",
        "\n",
        "                    # Save INT8 quantized model\n",
        "                    quantized_model_path = os.path.join(project_dir_enhanced_model, experiment_name + \"_stage2_qat\", 'quantized_model_int8.pth')\n",
        "                    torch.save(quantized_model.state_dict(), quantized_model_path)\n",
        "                    print(f\"✅ INT8 quantized model saved to: {quantized_model_path}\")\n",
        "\n",
        "                    # Export to TFLite for deployment\n",
        "                    export_model = YOLO(base_model_name)\n",
        "                    export_model.model.model = quantized_model\n",
        "                    export_model.model.nc = nc_from_yaml\n",
        "                    export_model.model.names = dict(enumerate(class_names_from_yaml))\n",
        "\n",
        "                    # NOTE: Make sure the model has the 'f' attribute before exporting\n",
        "                    if not hasattr(export_model.model.model, 'f'):\n",
        "                        export_model.model.model.f = -1\n",
        "\n",
        "                    tflite_path = os.path.join(project_dir_enhanced_model, experiment_name + \"_stage2_qat\", 'model_qat_int8.tflite')\n",
        "                    try:\n",
        "                        export_model.export(\n",
        "                            format='tflite',\n",
        "                            imgsz=image_size,\n",
        "                            int8=True,\n",
        "                            data=data_yaml,\n",
        "                            device='cpu',\n",
        "                            file=tflite_path\n",
        "                        )\n",
        "                        print(f\"✅ TFLite QAT-INT8 model exported: {tflite_path}\")\n",
        "                    except Exception as e_export:\n",
        "                        print(f\"❌ Export error: {e_export}\")\n",
        "                        print(\"Trying alternative export approach...\")\n",
        "                        # Try simplified export\n",
        "                        try:\n",
        "                            export_model.export(format='onnx', imgsz=image_size, simplify=True)\n",
        "                            print(\"✅ ONNX model exported as alternative\")\n",
        "                        except:\n",
        "                            print(\"❌ Alternative export also failed\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"\\n❌ ERROR DURING INT8 CONVERSION: {e}\")\n",
        "                    import traceback\n",
        "                    traceback.print_exc()\n",
        "            else:\n",
        "                print(f\"❌ Best QAT model weights not found: {best_qat_model_path}\")\n",
        "    else:\n",
        "        print(f\"❌ Best model from stage 1 not found: {best_model_path}\")\n",
        "else:\n",
        "    print(\"\\n❌ Stage 1 training failed. Skipping QAT and INT8 conversion.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lD46v5kaq27U",
        "outputId": "f5715275-3b78-4b2b-e155-584bf870f543"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Phase 5: Enhanced Main Script Logic with Improved Training\n",
            "======================================================================\n",
            "Initializing enhanced YOLOv12n model with improved architecture...\n",
            "\n",
            "Stage 1: Training without QAT (75 epochs)\n",
            "============================================\n",
            "Ultralytics 8.3.131 🚀 Python-3.11.12 torch-2.7.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.3, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/My Drive/SemesterProjectDatas/CombinedData/data.yaml, degrees=15.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.1, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.3, mode=train, model=yolo12n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=run_yolo12n_enhanced_improved_stage1, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=25, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/My Drive/SemesterProjectDatas/Model/Yolo12n/EnhancedYolo12n, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/My Drive/SemesterProjectDatas/Model/Yolo12n/EnhancedYolo12n/run_yolo12n_enhanced_improved_stage1, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.2, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=11\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  2    180864  ultralytics.nn.modules.block.A2C2f           [128, 128, 2, True, 4]        \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  2    689408  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 1]        \n",
            "  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 11                  -1  1     86912  ultralytics.nn.modules.block.A2C2f           [384, 128, 1, False, -1]      \n",
            " 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 14                  -1  1     24000  ultralytics.nn.modules.block.A2C2f           [256, 64, 1, False, -1]       \n",
            " 15                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 17                  -1  1     74624  ultralytics.nn.modules.block.A2C2f           [192, 128, 1, False, -1]      \n",
            " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 20                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 21        [14, 17, 20]  1    432817  ultralytics.nn.modules.head.Detect           [11, [64, 128, 256]]          \n",
            "YOLOv12n summary: 272 layers, 2,570,193 parameters, 2,570,177 gradients, 6.5 GFLOPs\n",
            "\n",
            "Transferred 0/691 items from pretrained weights\n",
            "Freezing layer 'model.21.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.4±0.0 ms, read: 32.5±20.1 MB/s, size: 63.4 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/SemesterProjectDatas/CombinedData/train/labels.cache... 6527 images, 1141 backgrounds, 0 corrupt: 100%|██████████| 6527/6527 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 9723, len(boxes) = 30435. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 1.0±0.4 ms, read: 27.3±24.7 MB/s, size: 108.3 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/SemesterProjectDatas/CombinedData/valid/labels.cache... 591 images, 96 backgrounds, 0 corrupt: 100%|██████████| 591/591 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 937, len(boxes) = 2808. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to /content/drive/My Drive/SemesterProjectDatas/Model/Yolo12n/EnhancedYolo12n/run_yolo12n_enhanced_improved_stage1/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 113 weight(decay=0.0), 120 weight(decay=0.0005), 119 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/My Drive/SemesterProjectDatas/Model/Yolo12n/EnhancedYolo12n/run_yolo12n_enhanced_improved_stage1\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      1/100      7.79G      3.734      4.926        2.7        303        640: 100%|██████████| 204/204 [00:48<00:00,  4.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:04<00:00,  2.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808    0.00024     0.0154   0.000124   1.67e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      2/100      9.31G      2.955      4.111      1.998        285        640: 100%|██████████| 204/204 [00:41<00:00,  4.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.496     0.0158     0.0141    0.00425\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      3/100      9.31G      2.718      3.847      1.853        202        640: 100%|██████████| 204/204 [00:39<00:00,  5.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.339     0.0565     0.0215     0.0077\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      4/100      9.33G      2.612      3.735      1.784        249        640: 100%|██████████| 204/204 [00:39<00:00,  5.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  4.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.345     0.0517     0.0228    0.00848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      5/100      9.33G      2.549      3.648      1.727        280        640: 100%|██████████| 204/204 [00:39<00:00,  5.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.371     0.0756     0.0256     0.0103\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      6/100      9.33G      2.479      3.582      1.695        214        640: 100%|██████████| 204/204 [00:39<00:00,  5.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.341     0.0816     0.0323     0.0134\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      7/100      9.33G      2.455      3.544      1.675        178        640: 100%|██████████| 204/204 [00:39<00:00,  5.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.351     0.0887     0.0284     0.0111\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      8/100      9.33G      2.417      3.504      1.662        274        640: 100%|██████████| 204/204 [00:39<00:00,  5.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.376     0.0773     0.0379     0.0154\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      9/100      9.33G      2.384      3.439      1.629        287        640: 100%|██████████| 204/204 [00:39<00:00,  5.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.339     0.0863     0.0356     0.0164\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     10/100      9.33G      2.367      3.417      1.615        309        640: 100%|██████████| 204/204 [00:39<00:00,  5.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808       0.35      0.108     0.0401     0.0161\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     11/100      9.33G      2.346      3.368        1.6        251        640: 100%|██████████| 204/204 [00:39<00:00,  5.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.353      0.108     0.0422     0.0188\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     12/100      9.34G      2.332       3.35      1.584        173        640: 100%|██████████| 204/204 [00:40<00:00,  5.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.356      0.108     0.0443     0.0186\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     13/100      9.34G      2.313      3.338       1.57        366        640: 100%|██████████| 204/204 [00:39<00:00,  5.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808       0.36      0.111     0.0466     0.0217\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     14/100      9.34G      2.302      3.311      1.577        323        640: 100%|██████████| 204/204 [00:39<00:00,  5.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.264      0.118     0.0459     0.0187\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     15/100      9.34G      2.291      3.307      1.574        212        640: 100%|██████████| 204/204 [00:39<00:00,  5.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.276      0.107     0.0472     0.0215\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     16/100      9.34G      2.278      3.254      1.546        172        640: 100%|██████████| 204/204 [00:39<00:00,  5.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.277      0.128     0.0473     0.0205\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     17/100      9.34G      2.274      3.243      1.562        330        640: 100%|██████████| 204/204 [00:39<00:00,  5.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  4.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.279      0.111     0.0508     0.0218\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     18/100      9.34G      2.261      3.219      1.538        301        640: 100%|██████████| 204/204 [00:39<00:00,  5.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.279      0.114     0.0513     0.0238\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     19/100      9.34G      2.247      3.192      1.536        308        640: 100%|██████████| 204/204 [00:39<00:00,  5.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.278      0.116     0.0536      0.022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     20/100      9.34G      2.245      3.216      1.532        238        640: 100%|██████████| 204/204 [00:39<00:00,  5.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.288      0.127     0.0512     0.0202\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     21/100      9.34G      2.241      3.184      1.542        200        640: 100%|██████████| 204/204 [00:39<00:00,  5.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.293      0.117     0.0598     0.0268\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     22/100      9.34G       2.23      3.189      1.526        239        640: 100%|██████████| 204/204 [00:39<00:00,  5.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.287      0.125     0.0603     0.0266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     23/100      9.34G      2.223      3.166      1.528        319        640: 100%|██████████| 204/204 [00:39<00:00,  5.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.275      0.119     0.0597     0.0284\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     24/100      9.34G       2.21       3.12      1.517        231        640: 100%|██████████| 204/204 [00:39<00:00,  5.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.372     0.0962     0.0521     0.0235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     25/100      9.34G       2.21      3.139      1.507        339        640: 100%|██████████| 204/204 [00:39<00:00,  5.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.278      0.138     0.0593     0.0247\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     26/100      9.34G      2.203      3.117      1.507        270        640: 100%|██████████| 204/204 [00:39<00:00,  5.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808       0.29      0.154     0.0617     0.0266\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     27/100      9.34G      2.198      3.117      1.511        187        640: 100%|██████████| 204/204 [00:39<00:00,  5.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.292      0.136     0.0628     0.0281\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     28/100      9.34G      2.191      3.086      1.508        289        640: 100%|██████████| 204/204 [00:39<00:00,  5.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.282      0.136     0.0651       0.03\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     29/100      9.34G      2.194      3.088      1.497        263        640: 100%|██████████| 204/204 [00:39<00:00,  5.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.299      0.137       0.07     0.0302\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     30/100      9.34G      2.186      3.072      1.489        234        640: 100%|██████████| 204/204 [00:39<00:00,  5.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.286      0.132     0.0657     0.0288\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     31/100      9.34G      2.183      3.076      1.493        207        640: 100%|██████████| 204/204 [00:39<00:00,  5.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.289       0.15     0.0697     0.0292\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     32/100      9.34G      2.184      3.062      1.498        221        640: 100%|██████████| 204/204 [00:39<00:00,  5.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.286      0.131     0.0648     0.0286\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     33/100      9.34G      2.182      3.064      1.503        200        640: 100%|██████████| 204/204 [00:39<00:00,  5.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.194      0.141     0.0673     0.0298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     34/100      9.34G      2.183      3.067      1.486        173        640: 100%|██████████| 204/204 [00:39<00:00,  5.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.283      0.149     0.0709     0.0305\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     35/100      9.34G      2.165      3.045       1.49        305        640: 100%|██████████| 204/204 [00:39<00:00,  5.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.224      0.152     0.0707      0.032\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     36/100      9.34G      2.142       2.99      1.466        254        640: 100%|██████████| 204/204 [00:39<00:00,  5.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.205      0.149     0.0697     0.0296\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     37/100      9.34G      2.159       3.02      1.482        283        640: 100%|██████████| 204/204 [00:39<00:00,  5.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.222      0.151     0.0777      0.035\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     38/100      9.34G      2.159      3.002      1.472        220        640: 100%|██████████| 204/204 [00:39<00:00,  5.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.225      0.149     0.0804      0.034\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     39/100      9.34G      2.172      3.024      1.482        164        640: 100%|██████████| 204/204 [00:39<00:00,  5.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.303      0.151     0.0758     0.0347\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     40/100      9.34G      2.158      3.001      1.472        172        640: 100%|██████████| 204/204 [00:39<00:00,  5.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.303       0.16     0.0748     0.0339\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     41/100      9.34G      2.151      2.987       1.48        177        640: 100%|██████████| 204/204 [00:39<00:00,  5.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.292      0.163     0.0732     0.0333\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     42/100      9.34G      2.143       2.98      1.464        167        640: 100%|██████████| 204/204 [00:39<00:00,  5.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.241      0.143     0.0789      0.035\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     43/100      9.34G      2.129      2.971      1.461        246        640: 100%|██████████| 204/204 [00:39<00:00,  5.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.204      0.156     0.0817     0.0377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     44/100      9.34G      2.147      2.963      1.464        296        640: 100%|██████████| 204/204 [00:39<00:00,  5.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.115       0.16     0.0814     0.0369\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     45/100      9.34G      2.146      2.966      1.465        219        640: 100%|██████████| 204/204 [00:39<00:00,  5.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.241      0.166     0.0787     0.0365\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     46/100      9.34G      2.135      2.935      1.467        222        640: 100%|██████████| 204/204 [00:39<00:00,  5.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.141      0.166     0.0831     0.0389\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     47/100      9.34G      2.124      2.932      1.455        181        640: 100%|██████████| 204/204 [00:39<00:00,  5.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.301      0.166     0.0834      0.038\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     48/100      9.34G      2.137      2.918      1.452        253        640: 100%|██████████| 204/204 [00:39<00:00,  5.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.206      0.167      0.084     0.0412\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     49/100      9.34G      2.124      2.909      1.438        299        640: 100%|██████████| 204/204 [00:39<00:00,  5.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.296      0.173     0.0852     0.0388\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     50/100      9.34G      2.132      2.921      1.448        143        640: 100%|██████████| 204/204 [00:39<00:00,  5.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.202      0.185     0.0871     0.0407\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     51/100      9.34G      2.125      2.913      1.457        173        640: 100%|██████████| 204/204 [00:39<00:00,  5.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.161      0.174     0.0874     0.0407\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     52/100      9.34G      2.114      2.896      1.446        263        640: 100%|██████████| 204/204 [00:39<00:00,  5.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.217       0.18     0.0861     0.0406\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     53/100      9.34G      2.132      2.903      1.454        322        640: 100%|██████████| 204/204 [00:39<00:00,  5.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808       0.15      0.156     0.0826     0.0378\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     54/100      9.34G      2.112      2.901      1.444        185        640: 100%|██████████| 204/204 [00:39<00:00,  5.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.154      0.178     0.0882     0.0417\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     55/100      9.34G      2.115      2.879      1.436        204        640: 100%|██████████| 204/204 [00:39<00:00,  5.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.264       0.18     0.0963      0.047\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     56/100      9.34G      2.101      2.875      1.447        196        640: 100%|██████████| 204/204 [00:39<00:00,  5.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.177      0.186     0.0895     0.0421\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     57/100      9.34G      2.098      2.863      1.428        252        640: 100%|██████████| 204/204 [00:39<00:00,  5.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808       0.16      0.186     0.0984     0.0448\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     58/100      9.34G      2.096      2.867      1.438        281        640: 100%|██████████| 204/204 [00:39<00:00,  5.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.247      0.178     0.0958     0.0474\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     59/100      9.34G      2.115      2.852      1.428        182        640: 100%|██████████| 204/204 [00:39<00:00,  5.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.194       0.19      0.099     0.0487\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     60/100      9.34G      2.087      2.858      1.433        203        640: 100%|██████████| 204/204 [00:39<00:00,  5.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.147      0.182     0.0965     0.0484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     61/100      9.34G      2.097       2.85      1.432        206        640: 100%|██████████| 204/204 [00:39<00:00,  5.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.168      0.183        0.1     0.0489\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     62/100      9.34G      2.092      2.854      1.435        187        640: 100%|██████████| 204/204 [00:39<00:00,  5.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.189        0.2        0.1     0.0506\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     63/100      9.34G      2.085      2.835      1.426        163        640: 100%|██████████| 204/204 [00:39<00:00,  5.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.161      0.191      0.107     0.0553\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     64/100      9.34G      2.088      2.825      1.427        243        640: 100%|██████████| 204/204 [00:39<00:00,  5.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.182      0.201     0.0997     0.0526\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     65/100      9.34G      2.084      2.822      1.423        365        640: 100%|██████████| 204/204 [00:39<00:00,  5.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.208      0.183     0.0991     0.0513\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     66/100      9.34G       2.06      2.799      1.417        213        640: 100%|██████████| 204/204 [00:39<00:00,  5.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.198      0.204      0.101     0.0539\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     67/100      9.34G      2.077      2.813      1.421        206        640: 100%|██████████| 204/204 [00:39<00:00,  5.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.161      0.196      0.104     0.0566\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     68/100      9.34G      2.068      2.805      1.405        318        640: 100%|██████████| 204/204 [00:39<00:00,  5.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.169      0.188      0.102     0.0569\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     69/100      9.34G      2.086      2.815      1.425        354        640: 100%|██████████| 204/204 [00:39<00:00,  5.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808       0.18      0.198      0.106     0.0577\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     70/100      9.34G      2.084      2.793      1.419        250        640: 100%|██████████| 204/204 [00:39<00:00,  5.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.185      0.202      0.105     0.0554\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     71/100      9.34G      2.074      2.776      1.404        256        640: 100%|██████████| 204/204 [00:39<00:00,  5.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808       0.16      0.191      0.103     0.0566\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     72/100      9.34G      2.059       2.77      1.401        225        640: 100%|██████████| 204/204 [00:39<00:00,  5.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.169      0.193      0.098     0.0525\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     73/100      9.34G       2.06      2.766      1.409        263        640: 100%|██████████| 204/204 [00:39<00:00,  5.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.177       0.18      0.102     0.0558\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     74/100      9.34G      2.065      2.764      1.407        222        640: 100%|██████████| 204/204 [00:39<00:00,  5.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.189      0.195      0.109     0.0598\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     75/100      9.34G      2.073      2.781      1.417        226        640: 100%|██████████| 204/204 [00:39<00:00,  5.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.199      0.198       0.11     0.0611\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     76/100      9.34G      2.052      2.755      1.398        194        640: 100%|██████████| 204/204 [00:39<00:00,  5.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.188      0.202      0.108     0.0597\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     77/100      9.34G      2.056      2.745      1.402        179        640: 100%|██████████| 204/204 [00:39<00:00,  5.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.288      0.188      0.109     0.0594\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     78/100      9.34G      2.057      2.755      1.401        204        640: 100%|██████████| 204/204 [00:39<00:00,  5.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.313      0.184      0.111     0.0617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     79/100      9.34G      2.046       2.75        1.4        318        640: 100%|██████████| 204/204 [00:39<00:00,  5.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808        0.2       0.18      0.109     0.0609\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     80/100      9.34G      2.058      2.735      1.399        299        640: 100%|██████████| 204/204 [00:38<00:00,  5.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.201      0.178       0.11     0.0615\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     81/100      9.34G      2.035      2.719      1.399        211        640: 100%|██████████| 204/204 [00:39<00:00,  5.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.194      0.181      0.108     0.0597\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     82/100      9.34G      2.048      2.752      1.402        254        640: 100%|██████████| 204/204 [00:39<00:00,  5.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.197      0.182      0.109     0.0611\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     83/100      9.34G      2.043      2.734      1.408        322        640: 100%|██████████| 204/204 [00:39<00:00,  5.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.192      0.192      0.106     0.0593\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     84/100      9.34G      2.055       2.71      1.395        304        640: 100%|██████████| 204/204 [00:39<00:00,  5.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.278      0.191       0.11     0.0612\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     85/100      9.34G      2.025      2.722      1.395        217        640: 100%|██████████| 204/204 [00:39<00:00,  5.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.285       0.19      0.114     0.0623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     86/100      9.34G       2.03      2.724      1.398        309        640: 100%|██████████| 204/204 [00:39<00:00,  5.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.307      0.178      0.117     0.0644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     87/100      9.34G      2.022      2.698      1.392        273        640: 100%|██████████| 204/204 [00:39<00:00,  5.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  4.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.288      0.172      0.119     0.0658\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     88/100      9.34G      2.032      2.714      1.394        173        640: 100%|██████████| 204/204 [00:39<00:00,  5.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.299      0.192      0.118      0.066\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     89/100      9.34G      2.052      2.725      1.383        323        640: 100%|██████████| 204/204 [00:39<00:00,  5.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.296       0.19      0.116     0.0653\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     90/100      9.34G      2.017      2.699      1.387        295        640: 100%|██████████| 204/204 [00:39<00:00,  5.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.285      0.182      0.115     0.0644\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     91/100      9.34G      1.919      2.485       1.31         94        640: 100%|██████████| 204/204 [00:38<00:00,  5.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.202      0.184      0.109     0.0619\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     92/100      9.34G      1.904      2.389      1.298         73        640: 100%|██████████| 204/204 [00:36<00:00,  5.58it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.297      0.199      0.115     0.0647\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     93/100      9.34G      1.895       2.38      1.302        134        640: 100%|██████████| 204/204 [00:36<00:00,  5.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.302        0.2      0.117     0.0664\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     94/100      9.34G       1.89      2.347      1.299        128        640: 100%|██████████| 204/204 [00:36<00:00,  5.63it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.299      0.199      0.121     0.0679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     95/100      9.34G      1.892      2.338      1.299        153        640: 100%|██████████| 204/204 [00:36<00:00,  5.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.289      0.203       0.12     0.0682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     96/100      9.34G      1.889      2.333      1.299        106        640: 100%|██████████| 204/204 [00:36<00:00,  5.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  4.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.283      0.202      0.121     0.0694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     97/100      9.34G      1.884       2.31      1.294        199        640: 100%|██████████| 204/204 [00:36<00:00,  5.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  4.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.276      0.198       0.12     0.0693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     98/100      9.34G      1.889      2.331      1.299         99        640: 100%|██████████| 204/204 [00:35<00:00,  5.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  4.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.272      0.202      0.121     0.0692\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     99/100      9.34G      1.891      2.307      1.297        121        640: 100%|██████████| 204/204 [00:36<00:00,  5.63it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  4.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.283      0.202      0.121     0.0696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    100/100      9.34G      1.881      2.302      1.298        111        640: 100%|██████████| 204/204 [00:36<00:00,  5.63it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  4.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808       0.28      0.208      0.122     0.0695\n",
            "\n",
            "100 epochs completed in 1.182 hours.\n",
            "Optimizer stripped from /content/drive/My Drive/SemesterProjectDatas/Model/Yolo12n/EnhancedYolo12n/run_yolo12n_enhanced_improved_stage1/weights/last.pt, 5.5MB\n",
            "Optimizer stripped from /content/drive/My Drive/SemesterProjectDatas/Model/Yolo12n/EnhancedYolo12n/run_yolo12n_enhanced_improved_stage1/weights/best.pt, 5.5MB\n",
            "\n",
            "Validating /content/drive/My Drive/SemesterProjectDatas/Model/Yolo12n/EnhancedYolo12n/run_yolo12n_enhanced_improved_stage1/weights/best.pt...\n",
            "Ultralytics 8.3.131 🚀 Python-3.11.12 torch-2.7.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "YOLOv12n summary (fused): 159 layers, 2,558,873 parameters, 0 gradients, 6.3 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:04<00:00,  2.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.277      0.204      0.122     0.0696\n",
            "                   Tin         43        100      0.281        0.3      0.215      0.142\n",
            "             cardboard         69        102      0.129      0.167     0.0771     0.0471\n",
            "       cigarette-butts         63        405      0.281    0.00741     0.0475     0.0179\n",
            "food-wrappers-packaging        123        214      0.266      0.444      0.236      0.142\n",
            "                litter        289       1640      0.287        0.3      0.189     0.0688\n",
            "                  mask          1          1          1          0     0.0415     0.0166\n",
            "           paper-items         40        112      0.162     0.0982     0.0738     0.0397\n",
            "          plastic-bags         25         32      0.105      0.188     0.0665     0.0306\n",
            "plastic-bottles-containers         91        119      0.223      0.395       0.21      0.137\n",
            " small-packaging-trash         55         61      0.288      0.295      0.171      0.121\n",
            "                 straw         21         22     0.0258     0.0455     0.0106    0.00393\n",
            "Speed: 0.1ms preprocess, 0.7ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/My Drive/SemesterProjectDatas/Model/Yolo12n/EnhancedYolo12n/run_yolo12n_enhanced_improved_stage1\u001b[0m\n",
            "✅ Stage 1 training completed successfully.\n",
            "\n",
            "Stage 2: QAT fine-tuning for 75 epochs\n",
            "=======================================\n",
            "Ultralytics 8.3.131 🚀 Python-3.11.12 torch-2.7.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=False, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.1, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/My Drive/SemesterProjectDatas/CombinedData/data.yaml, degrees=7.0, deterministic=True, device=0, dfl=2.0, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0003, lrf=0.001, mask_ratio=4, max_det=300, mixup=0.1, mode=train, model=/content/drive/My Drive/SemesterProjectDatas/Model/Yolo12n/EnhancedYolo12n/run_yolo12n_enhanced_improved_stage1/weights/best.pt, momentum=0.937, mosaic=0.8, multi_scale=False, name=run_yolo12n_enhanced_improved_stage2_qat, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=25, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/My Drive/SemesterProjectDatas/Model/Yolo12n/EnhancedYolo12n, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/My Drive/SemesterProjectDatas/Model/Yolo12n/EnhancedYolo12n/run_yolo12n_enhanced_improved_stage2_qat, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  2    180864  ultralytics.nn.modules.block.A2C2f           [128, 128, 2, True, 4]        \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  2    689408  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 1]        \n",
            "  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 11                  -1  1     86912  ultralytics.nn.modules.block.A2C2f           [384, 128, 1, False, -1]      \n",
            " 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 14                  -1  1     24000  ultralytics.nn.modules.block.A2C2f           [256, 64, 1, False, -1]       \n",
            " 15                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 17                  -1  1     74624  ultralytics.nn.modules.block.A2C2f           [192, 128, 1, False, -1]      \n",
            " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 20                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 21        [14, 17, 20]  1    432817  ultralytics.nn.modules.head.Detect           [11, [64, 128, 256]]          \n",
            "YOLOv12n summary: 272 layers, 2,570,193 parameters, 2,570,177 gradients, 6.5 GFLOPs\n",
            "\n",
            "Transferred 691/691 items from pretrained weights\n",
            "Freezing layer 'model.21.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 8.2±17.5 ms, read: 43.9±25.9 MB/s, size: 63.4 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/SemesterProjectDatas/CombinedData/train/labels.cache... 6527 images, 1141 backgrounds, 0 corrupt: 100%|██████████| 6527/6527 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 9723, len(boxes) = 30435. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (7.5GB RAM): 100%|██████████| 6527/6527 [00:48<00:00, 133.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.4±0.1 ms, read: 40.3±18.0 MB/s, size: 99.6 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/SemesterProjectDatas/CombinedData/valid/labels.cache... 591 images, 96 backgrounds, 0 corrupt: 100%|██████████| 591/591 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 937, len(boxes) = 2808. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.7GB RAM): 100%|██████████| 591/591 [00:01<00:00, 477.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to /content/drive/My Drive/SemesterProjectDatas/Model/Yolo12n/EnhancedYolo12n/run_yolo12n_enhanced_improved_stage2_qat/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0003, momentum=0.937) with parameter groups 113 weight(decay=0.0), 120 weight(decay=0.0005), 119 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/My Drive/SemesterProjectDatas/Model/Yolo12n/EnhancedYolo12n/run_yolo12n_enhanced_improved_stage2_qat\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      1/100      11.9G      2.009      2.622      1.796        217        640: 100%|██████████| 204/204 [00:41<00:00,  4.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808       0.13       0.12     0.0637     0.0342\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      2/100      14.2G      1.986      2.568      1.773        156        640: 100%|██████████| 204/204 [00:40<00:00,  5.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.175      0.188      0.105     0.0544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      3/100      14.2G      1.978      2.537      1.771        217        640: 100%|██████████| 204/204 [00:39<00:00,  5.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.275      0.191       0.11     0.0611\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      4/100      14.2G      1.967      2.523      1.764        127        640: 100%|██████████| 204/204 [00:39<00:00,  5.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.189      0.199      0.117     0.0662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      5/100      14.2G      1.957      2.504      1.755        236        640: 100%|██████████| 204/204 [00:39<00:00,  5.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.298      0.199      0.125     0.0701\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      6/100      14.2G      1.959      2.492      1.752        147        640: 100%|██████████| 204/204 [00:39<00:00,  5.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.161      0.204       0.11     0.0616\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      7/100      14.2G      1.947      2.471      1.743        151        640: 100%|██████████| 204/204 [00:39<00:00,  5.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.292      0.206       0.12     0.0659\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      8/100      14.2G      1.952      2.501      1.759        203        640: 100%|██████████| 204/204 [00:39<00:00,  5.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.302      0.209      0.131     0.0705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      9/100      14.2G      1.953      2.488      1.748        172        640: 100%|██████████| 204/204 [00:39<00:00,  5.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.289      0.198      0.112     0.0633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     10/100      14.2G      1.947      2.492       1.75        241        640: 100%|██████████| 204/204 [00:39<00:00,  5.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808       0.28      0.196      0.117     0.0642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     11/100      14.2G      1.945      2.464      1.748        210        640: 100%|██████████| 204/204 [00:39<00:00,  5.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.284      0.198       0.12     0.0665\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     12/100      14.2G      1.941      2.471      1.746        161        640: 100%|██████████| 204/204 [00:39<00:00,  5.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808       0.21       0.21      0.121     0.0683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     13/100      14.2G      1.943      2.475      1.754        196        640: 100%|██████████| 204/204 [00:39<00:00,  5.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.315      0.189      0.123     0.0677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     14/100      14.2G      1.929      2.454      1.737        185        640: 100%|██████████| 204/204 [00:39<00:00,  5.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.177      0.239      0.141     0.0748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     15/100      14.2G      1.933      2.461      1.747        247        640: 100%|██████████| 204/204 [00:39<00:00,  5.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.303      0.206       0.12      0.066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     16/100      14.2G      1.941       2.45      1.735        301        640: 100%|██████████| 204/204 [00:39<00:00,  5.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.182      0.209      0.123     0.0684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     17/100      14.2G      1.927      2.437      1.738        202        640: 100%|██████████| 204/204 [00:39<00:00,  5.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.185      0.215      0.116     0.0653\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     18/100      14.2G      1.942      2.459       1.74        169        640: 100%|██████████| 204/204 [00:39<00:00,  5.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.203      0.222      0.127     0.0718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     19/100      14.2G      1.938      2.444      1.737        196        640: 100%|██████████| 204/204 [00:39<00:00,  5.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.212      0.212      0.125     0.0686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     20/100      14.2G      1.926       2.44      1.731        162        640: 100%|██████████| 204/204 [00:39<00:00,  5.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808       0.31      0.205      0.129     0.0704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     21/100      14.2G      1.918      2.423      1.728        158        640: 100%|██████████| 204/204 [00:39<00:00,  5.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.212      0.206      0.138     0.0753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     22/100      14.2G       1.94      2.428      1.725        189        640: 100%|██████████| 204/204 [00:39<00:00,  5.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.306        0.2      0.124     0.0669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     23/100      14.2G      1.932      2.427      1.735        250        640: 100%|██████████| 204/204 [00:39<00:00,  5.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808       0.19      0.222      0.128      0.069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     24/100      14.2G      1.941      2.422      1.732        159        640: 100%|██████████| 204/204 [00:39<00:00,  5.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.288      0.213      0.139     0.0778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     25/100      14.2G       1.92      2.412      1.721        171        640: 100%|██████████| 204/204 [00:39<00:00,  5.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.194      0.249      0.152     0.0826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     26/100      14.2G      1.923      2.409      1.728        214        640: 100%|██████████| 204/204 [00:39<00:00,  5.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.234      0.208      0.135     0.0743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     27/100      14.2G       1.93      2.407      1.731        120        640: 100%|██████████| 204/204 [00:39<00:00,  5.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.197      0.199      0.119     0.0671\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     28/100      14.2G      1.938      2.435       1.74        207        640: 100%|██████████| 204/204 [00:39<00:00,  5.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.185      0.248      0.133     0.0718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     29/100      14.2G      1.925      2.411      1.715        309        640: 100%|██████████| 204/204 [00:39<00:00,  5.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.239      0.183      0.128     0.0714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     30/100      14.2G      1.913      2.388       1.71        235        640: 100%|██████████| 204/204 [00:39<00:00,  5.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.295      0.203      0.122      0.069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     31/100      14.2G      1.925      2.401      1.721        171        640: 100%|██████████| 204/204 [00:39<00:00,  5.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808       0.32      0.204       0.13     0.0743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     32/100      14.2G      1.922      2.394      1.723        179        640: 100%|██████████| 204/204 [00:39<00:00,  5.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.198      0.226      0.135     0.0726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     33/100      14.2G      1.916      2.387      1.724        193        640: 100%|██████████| 204/204 [00:39<00:00,  5.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.284      0.218      0.127     0.0713\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     34/100      14.2G      1.912      2.377      1.719        141        640: 100%|██████████| 204/204 [00:39<00:00,  5.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.173      0.238      0.137     0.0744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     35/100      14.2G      1.913      2.372      1.718        262        640: 100%|██████████| 204/204 [00:39<00:00,  5.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808        0.3      0.203      0.123     0.0685\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     36/100      14.2G      1.904      2.356      1.713        249        640: 100%|██████████| 204/204 [00:39<00:00,  5.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.201      0.221      0.126     0.0686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     37/100      14.2G      1.918      2.369      1.726        315        640: 100%|██████████| 204/204 [00:39<00:00,  5.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.173      0.237      0.136      0.074\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     38/100      14.2G      1.899      2.356      1.716        178        640: 100%|██████████| 204/204 [00:39<00:00,  5.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.192      0.223      0.138     0.0783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     39/100      14.2G      1.911      2.341      1.718        178        640: 100%|██████████| 204/204 [00:39<00:00,  5.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.211      0.208      0.138     0.0763\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     40/100      14.2G      1.909       2.33      1.708        198        640: 100%|██████████| 204/204 [00:39<00:00,  5.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.278      0.243      0.144     0.0768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     41/100      14.2G      1.899      2.347      1.712        232        640: 100%|██████████| 204/204 [00:39<00:00,  5.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.275      0.218       0.13     0.0729\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     42/100      14.2G      1.905      2.356      1.706        231        640: 100%|██████████| 204/204 [00:39<00:00,  5.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.216      0.204      0.124     0.0668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     43/100      14.2G      1.912       2.35      1.715        201        640: 100%|██████████| 204/204 [00:39<00:00,  5.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.352      0.182      0.137     0.0745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     44/100      14.2G        1.9      2.332      1.701        173        640: 100%|██████████| 204/204 [00:39<00:00,  5.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.189       0.24       0.14     0.0769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     45/100      14.2G      1.907      2.334      1.708        215        640: 100%|██████████| 204/204 [00:39<00:00,  5.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808       0.18      0.245      0.146     0.0784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     46/100      14.2G      1.906      2.341      1.711        136        640: 100%|██████████| 204/204 [00:39<00:00,  5.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.201      0.247      0.143     0.0781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     47/100      14.2G      1.915      2.322      1.705        137        640: 100%|██████████| 204/204 [00:39<00:00,  5.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.299      0.213      0.134     0.0743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     48/100      14.2G      1.901      2.332      1.713        238        640: 100%|██████████| 204/204 [00:39<00:00,  5.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.191      0.254      0.134     0.0722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     49/100      14.2G      1.885      2.314      1.705        221        640: 100%|██████████| 204/204 [00:39<00:00,  5.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.189      0.255      0.143     0.0774\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     50/100      14.2G      1.889      2.309      1.698        170        640: 100%|██████████| 204/204 [00:39<00:00,  5.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:02<00:00,  3.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.181       0.25      0.142     0.0764\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 25 epochs. Best results observed at epoch 25, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=25) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "50 epochs completed in 0.593 hours.\n",
            "Optimizer stripped from /content/drive/My Drive/SemesterProjectDatas/Model/Yolo12n/EnhancedYolo12n/run_yolo12n_enhanced_improved_stage2_qat/weights/last.pt, 5.5MB\n",
            "Optimizer stripped from /content/drive/My Drive/SemesterProjectDatas/Model/Yolo12n/EnhancedYolo12n/run_yolo12n_enhanced_improved_stage2_qat/weights/best.pt, 5.5MB\n",
            "\n",
            "Validating /content/drive/My Drive/SemesterProjectDatas/Model/Yolo12n/EnhancedYolo12n/run_yolo12n_enhanced_improved_stage2_qat/weights/best.pt...\n",
            "Ultralytics 8.3.131 🚀 Python-3.11.12 torch-2.7.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "YOLOv12n summary (fused): 159 layers, 2,558,873 parameters, 0 gradients, 6.3 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:04<00:00,  2.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808      0.195      0.248      0.152     0.0826\n",
            "                   Tin         43        100      0.253       0.28      0.212      0.148\n",
            "             cardboard         69        102      0.164      0.186     0.0959     0.0555\n",
            "       cigarette-butts         63        405      0.435     0.0399     0.0831     0.0316\n",
            "food-wrappers-packaging        123        214      0.227      0.481      0.226      0.132\n",
            "                litter        289       1640      0.222      0.345       0.19     0.0715\n",
            "                  mask          1          1          0          0      0.249     0.0995\n",
            "           paper-items         40        112       0.16      0.179     0.0824      0.039\n",
            "          plastic-bags         25         32      0.107      0.375     0.0905     0.0479\n",
            "plastic-bottles-containers         91        119      0.217      0.412      0.226      0.158\n",
            " small-packaging-trash         55         61      0.298      0.344      0.191      0.115\n",
            "                 straw         21         22     0.0601     0.0909     0.0263     0.0098\n",
            "Speed: 0.2ms preprocess, 1.2ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/My Drive/SemesterProjectDatas/Model/Yolo12n/EnhancedYolo12n/run_yolo12n_enhanced_improved_stage2_qat\u001b[0m\n",
            "✅ Stage 2 QAT training completed successfully.\n",
            "\n",
            "Performing post-training INT8 conversion...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/observer.py:244: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/observer.py:1333: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ INT8 quantized model saved to: /content/drive/My Drive/SemesterProjectDatas/Model/Yolo12n/EnhancedYolo12n/run_yolo12n_enhanced_improved_stage2_qat/quantized_model_int8.pth\n",
            "❌ Export error: '\u001b[31m\u001b[1mfile\u001b[0m' is not a valid YOLO argument. Similar arguments are i.e. ['profile=False'].\n",
            "\n",
            "    Arguments received: ['yolo', '-f', '/root/.local/share/jupyter/runtime/kernel-de2dcf6d-9fe0-445c-8ca5-73a885959c28.json']. Ultralytics 'yolo' commands use the following syntax:\n",
            "\n",
            "        yolo TASK MODE ARGS\n",
            "\n",
            "        Where   TASK (optional) is one of frozenset({'segment', 'classify', 'obb', 'detect', 'pose'})\n",
            "                MODE (required) is one of frozenset({'benchmark', 'track', 'train', 'predict', 'val', 'export'})\n",
            "                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n",
            "                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n",
            "\n",
            "    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n",
            "        yolo train data=coco8.yaml model=yolo11n.pt epochs=10 lr0=0.01\n",
            "\n",
            "    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n",
            "        yolo predict model=yolo11n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320\n",
            "\n",
            "    3. Val a pretrained detection model at batch-size 1 and image size 640:\n",
            "        yolo val model=yolo11n.pt data=coco8.yaml batch=1 imgsz=640\n",
            "\n",
            "    4. Export a YOLO11n classification model to ONNX format at image size 224 by 128 (no TASK required)\n",
            "        yolo export model=yolo11n-cls.pt format=onnx imgsz=224,128\n",
            "\n",
            "    5. Ultralytics solutions usage\n",
            "        yolo solutions count or in ['crop', 'blur', 'workout', 'heatmap', 'isegment', 'visioneye', 'speed', 'queue', 'analytics', 'inference', 'trackzone'] source=\"path/to/video.mp4\"\n",
            "\n",
            "    6. Run special commands:\n",
            "        yolo help\n",
            "        yolo checks\n",
            "        yolo version\n",
            "        yolo settings\n",
            "        yolo copy-cfg\n",
            "        yolo cfg\n",
            "        yolo solutions help\n",
            "\n",
            "    Docs: https://docs.ultralytics.com\n",
            "    Solutions: https://docs.ultralytics.com/solutions/\n",
            "    Community: https://community.ultralytics.com\n",
            "    GitHub: https://github.com/ultralytics/ultralytics\n",
            "    \n",
            "Trying alternative export approach...\n",
            "Ultralytics 8.3.131 🚀 Python-3.11.12 torch-2.7.0+cu126 CPU (Intel Xeon 2.20GHz)\n",
            "❌ Alternative export also failed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Final Validation and Benchmarking\n",
        "# ---------------------------------------------------------\n",
        "print(\"\\nPhase 6: Final Validation and Benchmarking\")\n",
        "print(\"=================================================\")\n",
        "\n",
        "try:\n",
        "    # Identify the best available model\n",
        "    if 'qat_training_successful' in locals() and qat_training_successful:\n",
        "        final_model_path = os.path.join(project_dir_enhanced_model, experiment_name + \"_stage2_qat\", 'weights', 'best.pt')\n",
        "        model_type = \"QAT-enhanced\"\n",
        "    elif 'stage1_successful' in locals() and stage1_successful:\n",
        "        final_model_path = os.path.join(project_dir_enhanced_model, experiment_name + \"_stage1\", 'weights', 'best.pt')\n",
        "        model_type = \"Enhanced (non-QAT)\"\n",
        "    else:\n",
        "        raise Exception(\"No successfully trained models available\")\n",
        "\n",
        "    # Load final model\n",
        "    print(f\"Loading {model_type} model for final validation: {final_model_path}\")\n",
        "    final_model = YOLO(final_model_path)\n",
        "\n",
        "    # Run comprehensive validation\n",
        "    print(\"Running detailed validation with multiple metrics...\")\n",
        "    val_results = final_model.val(\n",
        "        data=data_yaml,\n",
        "        imgsz=image_size,\n",
        "        batch=batch_size // 2,  # Smaller batch for validation\n",
        "        plots=True,\n",
        "        save_json=True,\n",
        "        save_conf=True,     # Save confidence scores\n",
        "        save_txt=True,      # Save labels\n",
        "        verbose=True,\n",
        "        conf=0.25,          # Lower confidence threshold to see more predictions\n",
        "        iou=0.65            # Slightly higher IoU threshold for better precision\n",
        "    )\n",
        "\n",
        "    print(f\"\\n✅ Final {model_type} model validation results:\")\n",
        "    print(f\"mAP50: {val_results.box.map50:.4f}\")\n",
        "    print(f\"mAP50-95: {val_results.box.map:.4f}\")\n",
        "    print(f\"Precision: {val_results.box.p:.4f}\")\n",
        "    print(f\"Recall: {val_results.box.r:.4f}\")\n",
        "\n",
        "    # Create per-class performance visualization\n",
        "    try:\n",
        "        print(\"\\nGenerating per-class performance visualization...\")\n",
        "        import matplotlib.pyplot as plt\n",
        "        import pandas as pd\n",
        "        import seaborn as sns\n",
        "\n",
        "        # Extract per-class metrics\n",
        "        classes = class_names_from_yaml\n",
        "        ap_per_class = val_results.box.maps.tolist() if hasattr(val_results.box, 'maps') else [0] * len(classes)\n",
        "        precision_per_class = val_results.box.p.tolist() if hasattr(val_results.box, 'p') else [0] * len(classes)\n",
        "        recall_per_class = val_results.box.r.tolist() if hasattr(val_results.box, 'r') else [0] * len(classes)\n",
        "\n",
        "        # Create dataframe for visualization\n",
        "        metrics_df = pd.DataFrame({\n",
        "            'Class': classes,\n",
        "            'AP': ap_per_class,\n",
        "            'Precision': precision_per_class,\n",
        "            'Recall': recall_per_class\n",
        "        })\n",
        "\n",
        "        # Sort by AP\n",
        "        metrics_df = metrics_df.sort_values('AP', ascending=False)\n",
        "\n",
        "        # Create heatmap\n",
        "        plt.figure(figsize=(14, 8))\n",
        "\n",
        "        # Convert to wide format for heatmap\n",
        "        heatmap_df = metrics_df.melt(id_vars=['Class'],\n",
        "                                     value_vars=['AP', 'Precision', 'Recall'],\n",
        "                                     var_name='Metric', value_name='Value')\n",
        "\n",
        "        # Create pivoted dataframe for heatmap\n",
        "        heatmap_pivot = heatmap_df.pivot(index='Class', columns='Metric', values='Value')\n",
        "\n",
        "        # Plot heatmap\n",
        "        sns.heatmap(heatmap_pivot, annot=True, cmap=\"YlGnBu\", fmt=\".3f\", vmin=0, vmax=1)\n",
        "        plt.title(f'Per-Class Performance Metrics - {model_type} Model', fontsize=16)\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Save figure\n",
        "        class_metrics_path = os.path.join(project_dir_enhanced_model,\n",
        "                             experiment_name + (\"_stage2_qat\" if 'qat_training_successful' in locals() and qat_training_successful else \"_stage1\"),\n",
        "                             'class_performance_heatmap.png')\n",
        "        plt.savefig(class_metrics_path, dpi=300, bbox_inches='tight')\n",
        "        print(f\"Per-class performance visualization saved to: {class_metrics_path}\")\n",
        "\n",
        "        # Also create a bar chart for easier comparison\n",
        "        plt.figure(figsize=(15, 10))\n",
        "        pos = np.arange(len(classes))\n",
        "        width = 0.25\n",
        "\n",
        "        plt.bar(pos - width, ap_per_class, width, alpha=0.7, color='#1f77b4', label='AP')\n",
        "        plt.bar(pos, precision_per_class, width, alpha=0.7, color='#ff7f0e', label='Precision')\n",
        "        plt.bar(pos + width, recall_per_class, width, alpha=0.7, color='#2ca02c', label='Recall')\n",
        "\n",
        "        plt.ylabel('Score', fontsize=14)\n",
        "        plt.title(f'Per-Class Performance Comparison - {model_type} Model', fontsize=16)\n",
        "        plt.xticks(pos, classes, rotation=45, ha='right')\n",
        "        plt.ylim(0, 1.0)\n",
        "        plt.legend(loc='upper right')\n",
        "        plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "        # Save bar chart\n",
        "        class_bar_path = os.path.join(project_dir_enhanced_model,\n",
        "                          experiment_name + (\"_stage2_qat\" if 'qat_training_successful' in locals() and qat_training_successful else \"_stage1\"),\n",
        "                          'class_performance_bars.png')\n",
        "        plt.savefig(class_bar_path, dpi=300, bbox_inches='tight')\n",
        "        print(f\"Per-class bar chart saved to: {class_bar_path}\")\n",
        "\n",
        "    except Exception as e_viz:\n",
        "        print(f\"Error creating visualizations: {e_viz}\")\n",
        "\n",
        "    # Benchmark speed on different batch sizes and image sizes\n",
        "    print(\"\\nRunning inference speed benchmarks...\")\n",
        "\n",
        "    benchmark_results = []\n",
        "    batch_sizes = [1, 4, 8]\n",
        "    img_sizes = [640, image_size]\n",
        "\n",
        "    for bs in batch_sizes:\n",
        "        for imgsz in img_sizes:\n",
        "            try:\n",
        "                # Run benchmark test\n",
        "                fps = final_model.predict(\n",
        "                    source=None,  # Use random tensor for benchmarking\n",
        "                    imgsz=imgsz,\n",
        "                    batch=bs,\n",
        "                    count=100,  # Number of frames to measure\n",
        "                    device=device_to_use,\n",
        "                    verbose=False\n",
        "                )\n",
        "                # Record result\n",
        "                benchmark_results.append({\n",
        "                    'Batch Size': bs,\n",
        "                    'Image Size': imgsz,\n",
        "                    'FPS': fps,\n",
        "                    'Model Type': model_type\n",
        "                })\n",
        "                print(f\"Batch size: {bs}, Image size: {imgsz}px - FPS: {fps:.1f}\")\n",
        "            except Exception as e_bench:\n",
        "                print(f\"Error during benchmark (BS={bs}, Size={imgsz}): {e_bench}\")\n",
        "\n",
        "    # Save benchmark results\n",
        "    if benchmark_results:\n",
        "        try:\n",
        "            benchmark_df = pd.DataFrame(benchmark_results)\n",
        "            benchmark_csv = os.path.join(project_dir_enhanced_model,\n",
        "                            experiment_name + (\"_stage2_qat\" if 'qat_training_successful' in locals() and qat_training_successful else \"_stage1\"),\n",
        "                            'benchmark_results.csv')\n",
        "            benchmark_df.to_csv(benchmark_csv, index=False)\n",
        "            print(f\"Benchmark results saved to: {benchmark_csv}\")\n",
        "\n",
        "            # Create benchmark visualization\n",
        "            plt.figure(figsize=(12, 8))\n",
        "            for size in img_sizes:\n",
        "                size_data = benchmark_df[benchmark_df['Image Size'] == size]\n",
        "                plt.plot(size_data['Batch Size'], size_data['FPS'],\n",
        "                         marker='o', linewidth=2, markersize=8,\n",
        "                         label=f'Image Size: {size}px')\n",
        "\n",
        "            plt.title(f'Inference Speed Benchmark - {model_type} Model', fontsize=16)\n",
        "            plt.xlabel('Batch Size', fontsize=14)\n",
        "            plt.ylabel('Frames Per Second (FPS)', fontsize=14)\n",
        "            plt.xticks(batch_sizes)\n",
        "            plt.grid(True, alpha=0.3)\n",
        "            plt.legend(fontsize=12)\n",
        "\n",
        "            benchmark_plot = os.path.join(project_dir_enhanced_model,\n",
        "                             experiment_name + (\"_stage2_qat\" if 'qat_training_successful' in locals() and qat_training_successful else \"_stage1\"),\n",
        "                             'benchmark_plot.png')\n",
        "            plt.savefig(benchmark_plot, dpi=300)\n",
        "            print(f\"Benchmark visualization saved to: {benchmark_plot}\")\n",
        "\n",
        "        except Exception as e_bench_viz:\n",
        "            print(f\"Error saving benchmark results: {e_bench_viz}\")\n",
        "\n",
        "    # Comparison with baseline model\n",
        "    print(\"\\nComparing with baseline YOLOv12n model...\")\n",
        "    try:\n",
        "        # Load baseline YOLOv12n\n",
        "        baseline_model = YOLO('yolo12n.pt')\n",
        "\n",
        "        # Validate baseline on same dataset\n",
        "        baseline_results = baseline_model.val(\n",
        "            data=data_yaml,\n",
        "            imgsz=640,  # Original size for baseline\n",
        "            batch=batch_size // 2,\n",
        "            verbose=False\n",
        "        )\n",
        "\n",
        "        # Print comparison\n",
        "        print(\"\\n📊 Performance Comparison:\")\n",
        "        print(f\"{'Metric':<12} {'Baseline':<10} {'Enhanced':<10} {'Improvement':<10}\")\n",
        "        print(\"-\" * 42)\n",
        "\n",
        "        baseline_map50 = baseline_results.box.map50 if hasattr(baseline_results.box, 'map50') else 0\n",
        "        enhanced_map50 = val_results.box.map50 if hasattr(val_results.box, 'map50') else 0\n",
        "        map50_improvement = enhanced_map50 - baseline_map50\n",
        "        map50_percent = (map50_improvement / max(baseline_map50, 0.001)) * 100\n",
        "\n",
        "        baseline_map = baseline_results.box.map if hasattr(baseline_results.box, 'map') else 0\n",
        "        enhanced_map = val_results.box.map if hasattr(val_results.box, 'map') else 0\n",
        "        map_improvement = enhanced_map - baseline_map\n",
        "        map_percent = (map_improvement / max(baseline_map, 0.001)) * 100\n",
        "\n",
        "        print(f\"{'mAP50':<12} {baseline_map50:.4f}{'':<4} {enhanced_map50:.4f}{'':<4} {map50_improvement:.4f} ({map50_percent:+.1f}%)\")\n",
        "        print(f\"{'mAP50-95':<12} {baseline_map:.4f}{'':<4} {enhanced_map:.4f}{'':<4} {map_improvement:.4f} ({map_percent:+.1f}%)\")\n",
        "\n",
        "        # Create comparison visualization\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        models = ['Baseline YOLOv12n', f'Enhanced {model_type}']\n",
        "        map50_values = [baseline_map50, enhanced_map50]\n",
        "        map_values = [baseline_map, enhanced_map]\n",
        "\n",
        "        x = np.arange(len(models))\n",
        "        width = 0.35\n",
        "\n",
        "        plt.bar(x - width/2, map50_values, width, label='mAP50', color='#1f77b4')\n",
        "        plt.bar(x + width/2, map_values, width, label='mAP50-95', color='#ff7f0e')\n",
        "\n",
        "        plt.ylabel('mAP Score', fontsize=14)\n",
        "        plt.title('Performance Comparison', fontsize=16)\n",
        "        plt.xticks(x, models)\n",
        "        plt.ylim(0, max(max(map50_values), max(map_values)) * 1.2)\n",
        "\n",
        "        # Add value labels on top of bars\n",
        "        for i, v in enumerate(map50_values):\n",
        "            plt.text(i - width/2, v + 0.01, f'{v:.4f}',\n",
        "                     ha='center', fontsize=10, fontweight='bold')\n",
        "\n",
        "        for i, v in enumerate(map_values):\n",
        "            plt.text(i + width/2, v + 0.01, f'{v:.4f}',\n",
        "                     ha='center', fontsize=10, fontweight='bold')\n",
        "\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "\n",
        "        comparison_plot = os.path.join(project_dir_enhanced_model,\n",
        "                           experiment_name + (\"_stage2_qat\" if 'qat_training_successful' in locals() and qat_training_successful else \"_stage1\"),\n",
        "                           'baseline_comparison.png')\n",
        "        plt.savefig(comparison_plot, dpi=300)\n",
        "        print(f\"Baseline comparison visualization saved to: {comparison_plot}\")\n",
        "\n",
        "    except Exception as e_compare:\n",
        "        print(f\"Error during baseline comparison: {e_compare}\")\n",
        "\n",
        "    print(\"\\n✅ Enhanced YOLOv12n model validation and benchmarking complete!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ ERROR DURING FINAL VALIDATION: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wg_oih7zq7hU",
        "outputId": "dc9a2ac9-6086-4b64-97f1-e7fed8f5b76a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Phase 6: Final Validation and Benchmarking\n",
            "=================================================\n",
            "Loading QAT-enhanced model for final validation: /content/drive/My Drive/SemesterProjectDatas/Model/Yolo12n/EnhancedYolo12n/run_yolo12n_enhanced_improved_stage2_qat/weights/best.pt\n",
            "Running detailed validation with multiple metrics...\n",
            "Ultralytics 8.3.131 🚀 Python-3.11.12 torch-2.7.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "YOLOv12n summary (fused): 159 layers, 2,558,873 parameters, 0 gradients, 6.3 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.3±0.1 ms, read: 62.9±21.3 MB/s, size: 90.8 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/SemesterProjectDatas/CombinedData/valid/labels.cache... 591 images, 96 backgrounds, 0 corrupt: 100%|██████████| 591/591 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 937, len(boxes) = 2808. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 37/37 [00:07<00:00,  5.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        591       2808       0.31      0.129      0.198      0.125\n",
            "                   Tin         43        100      0.392        0.2      0.298      0.236\n",
            "             cardboard         69        102      0.265     0.0882      0.158      0.108\n",
            "       cigarette-butts         63        405        0.8    0.00988      0.405      0.182\n",
            "food-wrappers-packaging        123        214      0.326      0.327      0.257      0.177\n",
            "                litter        289       1640      0.422      0.186       0.28      0.129\n",
            "                  mask          1          1          0          0          0          0\n",
            "           paper-items         40        112      0.125     0.0179     0.0655     0.0458\n",
            "          plastic-bags         25         32      0.125      0.125     0.0902      0.063\n",
            "plastic-bottles-containers         91        119      0.377      0.244      0.275      0.207\n",
            " small-packaging-trash         55         61      0.478       0.18      0.291      0.186\n",
            "                 straw         21         22        0.1     0.0455     0.0568     0.0397\n",
            "Speed: 0.5ms preprocess, 1.8ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
            "Saving runs/detect/val/predictions.json...\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n",
            "\n",
            "✅ Final QAT-enhanced model validation results:\n",
            "mAP50: 0.1978\n",
            "mAP50-95: 0.1249\n",
            "\n",
            "❌ ERROR DURING FINAL VALIDATION: unsupported format string passed to numpy.ndarray.__format__\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-15-6f15a4267334>\", line 39, in <cell line: 0>\n",
            "    print(f\"Precision: {val_results.box.p:.4f}\")\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "TypeError: unsupported format string passed to numpy.ndarray.__format__\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Verify and Export INT8 Model\n",
        "# ---------------------------------------------------------\n",
        "print(\"\\nPhase 7: Verify and Export INT8 Model for Deployment\")\n",
        "print(\"=================================================\")\n",
        "\n",
        "# Determine the best available INT8 model\n",
        "int8_model_path = None\n",
        "\n",
        "if 'qat_training_successful' in locals() and qat_training_successful:\n",
        "    int8_model_path = os.path.join(project_dir_enhanced_model,\n",
        "                     experiment_name + \"_stage2_qat\",\n",
        "                     'quantized_model_int8.pth')\n",
        "else:\n",
        "    # Look for other INT8 models in the project directory\n",
        "    for root, dirs, files in os.walk(project_dir_enhanced_model):\n",
        "        for file in files:\n",
        "            if file.endswith('int8.pth'):\n",
        "                int8_model_path = os.path.join(root, file)\n",
        "                break\n",
        "        if int8_model_path:\n",
        "            break\n",
        "\n",
        "if int8_model_path and os.path.exists(int8_model_path):\n",
        "    print(f\"Found INT8 model at: {int8_model_path}\")\n",
        "\n",
        "    try:\n",
        "        # Initialize base model and custom architecture\n",
        "        print(\"Loading INT8 model for verification...\")\n",
        "        base_model = YOLO(base_model_name)\n",
        "\n",
        "        # Create custom model with the right architecture\n",
        "        int8_model = CustomEnhancedYOLOModel(\n",
        "            base_model_instance=base_model,\n",
        "            nc=nc_from_yaml\n",
        "        )\n",
        "\n",
        "        # Prepare for INT8\n",
        "        int8_model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
        "        torch.quantization.prepare(int8_model, inplace=True)\n",
        "        int8_model = torch.quantization.convert(int8_model, inplace=False)\n",
        "\n",
        "        # Load the saved INT8 weights\n",
        "        int8_model.load_state_dict(torch.load(int8_model_path))\n",
        "        int8_model.eval()\n",
        "\n",
        "        # Wrap in YOLO container for export\n",
        "        export_model = YOLO(base_model_name)\n",
        "        export_model.model.model = int8_model\n",
        "        export_model.model.nc = nc_from_yaml\n",
        "        export_model.model.names = dict(enumerate(class_names_from_yaml))\n",
        "\n",
        "        # Ensure 'f' attribute is set for export\n",
        "        if not hasattr(int8_model, 'f'):\n",
        "            int8_model.f = -1\n",
        "\n",
        "        # Try multiple export formats\n",
        "        export_formats = ['tflite', 'onnx', 'torchscript']\n",
        "\n",
        "        for format in export_formats:\n",
        "            try:\n",
        "                print(f\"\\nExporting to {format.upper()}...\")\n",
        "                if format == 'tflite':\n",
        "                    export_path = export_model.export(\n",
        "                        format=format,\n",
        "                        imgsz=640,  # Use standard size for compatibility\n",
        "                        int8=True,\n",
        "                        data=data_yaml,\n",
        "                        device='cpu'\n",
        "                    )\n",
        "                else:\n",
        "                    export_path = export_model.export(\n",
        "                        format=format,\n",
        "                        imgsz=640,\n",
        "                        device='cpu',\n",
        "                        simplify=True\n",
        "                    )\n",
        "                print(f\"✅ Successfully exported to {format.upper()}: {export_path}\")\n",
        "\n",
        "                # Create optimized export for edge devices if TFLite\n",
        "                if format == 'tflite' and export_path:\n",
        "                    try:\n",
        "                        # For edge devices, create an optimized version\n",
        "                        import tensorflow as tf\n",
        "\n",
        "                        # Load the TFLite model\n",
        "                        converter = tf.lite.TFLiteConverter.from_saved_model(export_path)\n",
        "\n",
        "                        # Add optimization flags\n",
        "                        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "                        converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "                        converter.target_spec.supported_types = [tf.int8]\n",
        "                        converter.inference_input_type = tf.uint8\n",
        "                        converter.inference_output_type = tf.uint8\n",
        "\n",
        "                        # Generate optimized model\n",
        "                        optimized_model = converter.convert()\n",
        "\n",
        "                        # Save the optimized model\n",
        "                        optimized_path = export_path.replace('.tflite', '_optimized.tflite')\n",
        "                        with open(optimized_path, 'wb') as f:\n",
        "                            f.write(optimized_model)\n",
        "\n",
        "                        print(f\"✅ Created optimized TFLite model for edge devices: {optimized_path}\")\n",
        "                    except Exception as e_opt:\n",
        "                        print(f\"⚠️ Could not optimize TFLite model: {e_opt}\")\n",
        "\n",
        "            except Exception as e_exp:\n",
        "                print(f\"⚠️ Failed to export to {format}: {e_exp}\")\n",
        "\n",
        "        print(\"\\n✅ INT8 model export process completed!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error during INT8 model verification and export: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "else:\n",
        "    print(\"❌ No INT8 model found. Run the training with QAT first.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXJiPF2VrA58",
        "outputId": "636253ab-70f5-44cb-ca8c-e6e17d1873ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Phase 7: Verify and Export INT8 Model for Deployment\n",
            "=================================================\n",
            "Found INT8 model at: /content/drive/My Drive/SemesterProjectDatas/Model/Yolo12n/EnhancedYolo12n/run_yolo12n_enhanced_improved_stage2_qat/quantized_model_int8.pth\n",
            "Loading INT8 model for verification...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/observer.py:244: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/observer.py:1333: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Error during INT8 model verification and export: 'cbam_p3.mlp.0.bias'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/_utils.py:446: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  device=storage.device,\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-16-11c330dc9919>\", line 43, in <cell line: 0>\n",
            "    int8_model.load_state_dict(torch.load(int8_model_path))\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 2573, in load_state_dict\n",
            "    load(self, state_dict)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 2561, in load\n",
            "    load(child, child_state_dict, child_prefix)  # noqa: F821\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 2561, in load\n",
            "    load(child, child_state_dict, child_prefix)  # noqa: F821\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 2561, in load\n",
            "    load(child, child_state_dict, child_prefix)  # noqa: F821\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 2544, in load\n",
            "    module._load_from_state_dict(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/ao/nn/quantized/modules/conv.py\", line 200, in _load_from_state_dict\n",
            "    self.set_weight_bias(state_dict[prefix + \"weight\"], state_dict[prefix + \"bias\"])\n",
            "                                                        ~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
            "KeyError: 'cbam_p3.mlp.0.bias'\n"
          ]
        }
      ]
    }
  ]
}